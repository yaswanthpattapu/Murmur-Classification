{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda:7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2015-present, Facebook, Inc.\n",
    "# All rights reserved.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "from torch import Tensor\n",
    "from typing import Optional\n",
    "\n",
    "from timm.models.vision_transformer import VisionTransformer, _cfg\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.layers import trunc_normal_, lecun_normal_\n",
    "\n",
    "from timm.models.layers import DropPath, to_2tuple\n",
    "from timm.models.vision_transformer import _load_weights\n",
    "\n",
    "import math\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "# from mamba_ssm.modules.mamba_simple import Mamba\n",
    "# from mamba_ssm.utils.generation import GenerationMixin\n",
    "# from mamba_ssm.utils.hf import load_config_hf, load_state_dict_hf\n",
    "\n",
    "from rope import *\n",
    "import random\n",
    "\n",
    "try:\n",
    "    from mamba_ssm.ops.triton.layernorm import RMSNorm, layer_norm_fn, rms_norm_fn\n",
    "except ImportError:\n",
    "    RMSNorm, layer_norm_fn, rms_norm_fn = None, None, None\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    'vim_tiny_patch16_224', 'vim_small_patch16_224', 'vim_base_patch16_224',\n",
    "    'vim_tiny_patch16_384', 'vim_small_patch16_384', 'vim_base_patch16_384',\n",
    "]\n",
    "\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\" 2D Image to Patch Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, stride=16, in_chans=3, embed_dim=768, norm_layer=None, flatten=True, **kwargs):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.grid_size = ((img_size[0] - patch_size[0]) // stride + 1, (img_size[1] - patch_size[1]) // stride + 1)\n",
    "        self.num_patches = self.grid_size[0] * self.grid_size[1]\n",
    "        self.flatten = flatten\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=stride)\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        x = self.proj(x)\n",
    "        if self.flatten:\n",
    "            x = x.flatten(2).transpose(1, 2)  # BCHW -> BNC\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(\n",
    "        self, dim, mixer_cls, norm_cls=nn.LayerNorm, fused_add_norm=False, residual_in_fp32=False,drop_path=0.,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Simple block wrapping a mixer class with LayerNorm/RMSNorm and residual connection\"\n",
    "\n",
    "        This Block has a slightly different structure compared to a regular\n",
    "        prenorm Transformer block.\n",
    "        The standard block is: LN -> MHA/MLP -> Add.\n",
    "        [Ref: https://arxiv.org/abs/2002.04745]\n",
    "        Here we have: Add -> LN -> Mixer, returning both\n",
    "        the hidden_states (output of the mixer) and the residual.\n",
    "        This is purely for performance reasons, as we can fuse add and LayerNorm.\n",
    "        The residual needs to be provided (except for the very first block).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.residual_in_fp32 = residual_in_fp32\n",
    "        self.fused_add_norm = fused_add_norm\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        self.mixer = mixer_cls(dim)\n",
    "        self.norm = norm_cls(dim)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        if self.fused_add_norm:\n",
    "            assert RMSNorm is not None, \"RMSNorm import fails\"\n",
    "            assert isinstance(\n",
    "                self.norm, (nn.LayerNorm, RMSNorm)\n",
    "            ), \"Only LayerNorm and RMSNorm are supported for fused_add_norm\"\n",
    "\n",
    "    def forward(\n",
    "        self, hidden_states: Tensor, residual: Optional[Tensor] = None, inference_params=None\n",
    "    ):\n",
    "        r\"\"\"Pass the input through the encoder layer.\n",
    "\n",
    "        Args:\n",
    "            hidden_states: the sequence to the encoder layer (required).\n",
    "            residual: hidden_states = Mixer(LN(residual))\n",
    "        \"\"\"\n",
    "        if not self.fused_add_norm:\n",
    "            if residual is None:\n",
    "                residual = hidden_states\n",
    "            else:\n",
    "                residual = residual + self.drop_path(hidden_states)\n",
    "            \n",
    "            hidden_states = self.norm(residual.to(dtype=self.norm.weight.dtype))\n",
    "            if self.residual_in_fp32:\n",
    "                residual = residual.to(torch.float32)\n",
    "        else:\n",
    "            fused_add_norm_fn = rms_norm_fn if isinstance(self.norm, RMSNorm) else layer_norm_fn\n",
    "            if residual is None:\n",
    "                hidden_states, residual = fused_add_norm_fn(\n",
    "                    hidden_states,\n",
    "                    self.norm.weight,\n",
    "                    self.norm.bias,\n",
    "                    residual=residual,\n",
    "                    prenorm=True,\n",
    "                    residual_in_fp32=self.residual_in_fp32,\n",
    "                    eps=self.norm.eps,\n",
    "                )\n",
    "            else:\n",
    "                hidden_states, residual = fused_add_norm_fn(\n",
    "                    self.drop_path(hidden_states),\n",
    "                    self.norm.weight,\n",
    "                    self.norm.bias,\n",
    "                    residual=residual,\n",
    "                    prenorm=True,\n",
    "                    residual_in_fp32=self.residual_in_fp32,\n",
    "                    eps=self.norm.eps,\n",
    "                )    \n",
    "        hidden_states = self.mixer(hidden_states, inference_params=inference_params)\n",
    "        return hidden_states, residual\n",
    "\n",
    "    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, **kwargs):\n",
    "        return self.mixer.allocate_inference_cache(batch_size, max_seqlen, dtype=dtype, **kwargs)\n",
    "\n",
    "\n",
    "def create_block(\n",
    "    d_model,\n",
    "    d_state=16,\n",
    "    ssm_cfg=None,\n",
    "    norm_epsilon=1e-5,\n",
    "    drop_path=0.,\n",
    "    rms_norm=False,\n",
    "    residual_in_fp32=False,\n",
    "    fused_add_norm=False,\n",
    "    layer_idx=None,\n",
    "    device=None,\n",
    "    dtype=None,\n",
    "    if_bimamba=False,\n",
    "    bimamba_type=\"none\",\n",
    "    if_divide_out=False,\n",
    "    init_layer_scale=None,\n",
    "):\n",
    "    if if_bimamba:\n",
    "        bimamba_type = \"v1\"\n",
    "    if ssm_cfg is None:\n",
    "        ssm_cfg = {}\n",
    "    factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    # mixer_cls = partial(Mamba, d_state=d_state, layer_idx=layer_idx, bimamba_type=bimamba_type, if_divide_out=if_divide_out, init_layer_scale=init_layer_scale, **ssm_cfg, **factory_kwargs)\n",
    "    mixer_cls = partial(Mamba, d_state=d_state, layer_idx=layer_idx, **ssm_cfg, **factory_kwargs)\n",
    "    norm_cls = partial(\n",
    "        nn.LayerNorm if not rms_norm else RMSNorm, eps=norm_epsilon, **factory_kwargs\n",
    "    )\n",
    "    block = Block(\n",
    "        d_model,\n",
    "        mixer_cls,\n",
    "        norm_cls=norm_cls,\n",
    "        drop_path=drop_path,\n",
    "        fused_add_norm=fused_add_norm,\n",
    "        residual_in_fp32=residual_in_fp32,\n",
    "    )\n",
    "    block.layer_idx = layer_idx\n",
    "    return block\n",
    "\n",
    "\n",
    "# https://github.com/huggingface/transformers/blob/c28d04e9e252a1a099944e325685f14d242ecdcd/src/transformers/models/gpt2/modeling_gpt2.py#L454\n",
    "def _init_weights(\n",
    "    module,\n",
    "    n_layer,\n",
    "    initializer_range=0.02,  # Now only used for embedding layer.\n",
    "    rescale_prenorm_residual=True,\n",
    "    n_residuals_per_layer=1,  # Change to 2 if we have MLP\n",
    "):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        if module.bias is not None:\n",
    "            if not getattr(module.bias, \"_no_reinit\", False):\n",
    "                nn.init.zeros_(module.bias)\n",
    "    elif isinstance(module, nn.Embedding):\n",
    "        nn.init.normal_(module.weight, std=initializer_range)\n",
    "\n",
    "    if rescale_prenorm_residual:\n",
    "        # Reinitialize selected weights subject to the OpenAI GPT-2 Paper Scheme:\n",
    "        #   > A modified initialization which accounts for the accumulation on the residual path with model depth. Scale\n",
    "        #   > the weights of residual layers at initialization by a factor of 1/√N where N is the # of residual layers.\n",
    "        #   >   -- GPT-2 :: https://openai.com/blog/better-language-models/\n",
    "        #\n",
    "        # Reference (Megatron-LM): https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/model/gpt_model.py\n",
    "        for name, p in module.named_parameters():\n",
    "            if name in [\"out_proj.weight\", \"fc2.weight\"]:\n",
    "                # Special Scaled Initialization --> There are 2 Layer Norms per Transformer Block\n",
    "                # Following Pytorch init, except scale by 1/sqrt(2 * n_layer)\n",
    "                # We need to reinit p since this code could be called multiple times\n",
    "                # Having just p *= scale would repeatedly scale it down\n",
    "                nn.init.kaiming_uniform_(p, a=math.sqrt(5))\n",
    "                with torch.no_grad():\n",
    "                    p /= math.sqrt(n_residuals_per_layer * n_layer)\n",
    "\n",
    "\n",
    "def segm_init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        trunc_normal_(m.weight, std=0.02)\n",
    "        if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        # NOTE conv was left to pytorch default in my original init\n",
    "        lecun_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, (nn.LayerNorm, nn.GroupNorm, nn.BatchNorm2d)):\n",
    "        nn.init.zeros_(m.bias)\n",
    "        nn.init.ones_(m.weight)\n",
    "\n",
    "\n",
    "class VisionMamba(nn.Module):\n",
    "    def __init__(self, \n",
    "                 img_size=224, \n",
    "                 patch_size=16, \n",
    "                 stride=16,\n",
    "                 depth=24, \n",
    "                 embed_dim=192, \n",
    "                 d_state=16,\n",
    "                 channels=3, \n",
    "                 num_classes=1000,\n",
    "                 ssm_cfg=None, \n",
    "                 drop_rate=0.,\n",
    "                 drop_path_rate=0.1,\n",
    "                 norm_epsilon: float = 1e-5, \n",
    "                 rms_norm: bool = True, \n",
    "                 initializer_cfg=None,\n",
    "                 fused_add_norm=True,\n",
    "                 residual_in_fp32=True,\n",
    "                 device=None,\n",
    "                 dtype=None,\n",
    "                 ft_seq_len=None,\n",
    "                 pt_hw_seq_len=14,\n",
    "                 if_bidirectional=False,\n",
    "                 final_pool_type='none',\n",
    "                 if_abs_pos_embed=True,\n",
    "                 if_rope=False,\n",
    "                 if_rope_residual=False,\n",
    "                 flip_img_sequences_ratio=-1.,\n",
    "                 if_bimamba=False,\n",
    "                 bimamba_type=\"v2\",\n",
    "                 if_cls_token=True,\n",
    "                 if_divide_out=True,\n",
    "                 init_layer_scale=None,\n",
    "                 use_double_cls_token=False,\n",
    "                 use_middle_cls_token=True,\n",
    "                 **kwargs):\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        # add factory_kwargs into kwargs\n",
    "        kwargs.update(factory_kwargs) \n",
    "        super().__init__()\n",
    "        self.residual_in_fp32 = residual_in_fp32\n",
    "        self.fused_add_norm = fused_add_norm\n",
    "        self.if_bidirectional = if_bidirectional\n",
    "        self.final_pool_type = final_pool_type\n",
    "        self.if_abs_pos_embed = if_abs_pos_embed\n",
    "        self.if_rope = if_rope\n",
    "        self.if_rope_residual = if_rope_residual\n",
    "        self.flip_img_sequences_ratio = flip_img_sequences_ratio\n",
    "        self.if_cls_token = if_cls_token\n",
    "        self.use_double_cls_token = use_double_cls_token\n",
    "        self.use_middle_cls_token = use_middle_cls_token\n",
    "        self.num_tokens = 1 if if_cls_token else 0\n",
    "\n",
    "        # pretrain parameters\n",
    "        self.num_classes = num_classes\n",
    "        self.d_model = self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
    "\n",
    "        # self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, stride=stride, in_chans=channels, embed_dim=embed_dim)\n",
    "        self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_chans=channels, embed_dim=embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "\n",
    "        if if_cls_token:\n",
    "            if use_double_cls_token:\n",
    "                self.cls_token_head = nn.Parameter(torch.zeros(1, 1, self.embed_dim))\n",
    "                self.cls_token_tail = nn.Parameter(torch.zeros(1, 1, self.embed_dim))\n",
    "                self.num_tokens = 2\n",
    "            else:\n",
    "                self.cls_token = nn.Parameter(torch.zeros(1, 1, self.embed_dim))\n",
    "                # self.num_tokens = 1\n",
    "            \n",
    "        if if_abs_pos_embed:\n",
    "            self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + self.num_tokens, self.embed_dim))\n",
    "            self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        if if_rope:\n",
    "            half_head_dim = embed_dim // 2\n",
    "            hw_seq_len = img_size // patch_size\n",
    "            self.rope = VisionRotaryEmbeddingFast(\n",
    "                dim=half_head_dim,\n",
    "                pt_seq_len=pt_hw_seq_len,\n",
    "                ft_seq_len=hw_seq_len\n",
    "            )\n",
    "        self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "\n",
    "        # TODO: release this comment\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "        # import ipdb;ipdb.set_trace()\n",
    "        inter_dpr = [0.0] + dpr\n",
    "        self.drop_path = DropPath(drop_path_rate) if drop_path_rate > 0. else nn.Identity()\n",
    "                # transformer blocks\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                create_block(\n",
    "                    embed_dim,\n",
    "                    d_state=d_state,\n",
    "                    ssm_cfg=ssm_cfg,\n",
    "                    norm_epsilon=norm_epsilon,\n",
    "                    rms_norm=rms_norm,\n",
    "                    residual_in_fp32=residual_in_fp32,\n",
    "                    fused_add_norm=fused_add_norm,\n",
    "                    layer_idx=i,\n",
    "                    if_bimamba=if_bimamba,\n",
    "                    bimamba_type=bimamba_type,\n",
    "                    drop_path=inter_dpr[i],\n",
    "                    if_divide_out=if_divide_out,\n",
    "                    init_layer_scale=init_layer_scale,\n",
    "                    **factory_kwargs,\n",
    "                )\n",
    "                for i in range(depth)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # output head\n",
    "        self.norm_f = (nn.LayerNorm if not rms_norm else RMSNorm)(\n",
    "            embed_dim, eps=norm_epsilon, **factory_kwargs\n",
    "        )\n",
    "\n",
    "        # self.pre_logits = nn.Identity()\n",
    "\n",
    "        # original init\n",
    "        self.patch_embed.apply(segm_init_weights)\n",
    "        self.head.apply(segm_init_weights)\n",
    "        if if_abs_pos_embed:\n",
    "            trunc_normal_(self.pos_embed, std=.02)\n",
    "        if if_cls_token:\n",
    "            if use_double_cls_token:\n",
    "                trunc_normal_(self.cls_token_head, std=.02)\n",
    "                trunc_normal_(self.cls_token_tail, std=.02)\n",
    "            else:\n",
    "                trunc_normal_(self.cls_token, std=.02)\n",
    "\n",
    "        # mamba init\n",
    "        self.apply(\n",
    "            partial(\n",
    "                _init_weights,\n",
    "                n_layer=depth,\n",
    "                **(initializer_cfg if initializer_cfg is not None else {}),\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, **kwargs):\n",
    "        return {\n",
    "            i: layer.allocate_inference_cache(batch_size, max_seqlen, dtype=dtype, **kwargs)\n",
    "            for i, layer in enumerate(self.layers)\n",
    "        }\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {\"pos_embed\", \"cls_token\", \"dist_token\", \"cls_token_head\", \"cls_token_tail\"}\n",
    "\n",
    "    @torch.jit.ignore()\n",
    "    def load_pretrained(self, checkpoint_path, prefix=\"\"):\n",
    "        _load_weights(self, checkpoint_path, prefix)\n",
    "\n",
    "    def forward_features(self, x, inference_params=None, if_random_cls_token_position=False, if_random_token_rank=False):\n",
    "        # taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n",
    "        # with slight modifications to add the dist_token\n",
    "        x = self.patch_embed(x)\n",
    "        B, M, _ = x.shape\n",
    "\n",
    "        if self.if_cls_token:\n",
    "            if self.use_double_cls_token:\n",
    "                cls_token_head = self.cls_token_head.expand(B, -1, -1)\n",
    "                cls_token_tail = self.cls_token_tail.expand(B, -1, -1)\n",
    "                token_position = [0, M + 1]\n",
    "                x = torch.cat((cls_token_head, x, cls_token_tail), dim=1)\n",
    "                M = x.shape[1]\n",
    "            else:\n",
    "                if self.use_middle_cls_token:\n",
    "                    cls_token = self.cls_token.expand(B, -1, -1)\n",
    "                    token_position = M // 2\n",
    "                    # add cls token in the middle\n",
    "                    x = torch.cat((x[:, :token_position, :], cls_token, x[:, token_position:, :]), dim=1)\n",
    "                elif if_random_cls_token_position:\n",
    "                    cls_token = self.cls_token.expand(B, -1, -1)\n",
    "                    token_position = random.randint(0, M)\n",
    "                    x = torch.cat((x[:, :token_position, :], cls_token, x[:, token_position:, :]), dim=1)\n",
    "                    print(\"token_position: \", token_position)\n",
    "                else:\n",
    "                    cls_token = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "                    token_position = 0\n",
    "                    x = torch.cat((cls_token, x), dim=1)\n",
    "                M = x.shape[1]\n",
    "\n",
    "        if self.if_abs_pos_embed:\n",
    "            # if new_grid_size[0] == self.patch_embed.grid_size[0] and new_grid_size[1] == self.patch_embed.grid_size[1]:\n",
    "            #     x = x + self.pos_embed\n",
    "            # else:\n",
    "            #     pos_embed = interpolate_pos_embed_online(\n",
    "            #                 self.pos_embed, self.patch_embed.grid_size, new_grid_size,0\n",
    "            #             )\n",
    "            x = x + self.pos_embed\n",
    "            x = self.pos_drop(x)\n",
    "\n",
    "        if if_random_token_rank:\n",
    "\n",
    "            # 生成随机 shuffle 索引\n",
    "            shuffle_indices = torch.randperm(M)\n",
    "\n",
    "            if isinstance(token_position, list):\n",
    "                print(\"original value: \", x[0, token_position[0], 0], x[0, token_position[1], 0])\n",
    "            else:\n",
    "                print(\"original value: \", x[0, token_position, 0])\n",
    "            print(\"original token_position: \", token_position)\n",
    "\n",
    "            # 执行 shuffle\n",
    "            x = x[:, shuffle_indices, :]\n",
    "\n",
    "            if isinstance(token_position, list):\n",
    "                # 找到 cls token 在 shuffle 之后的新位置\n",
    "                new_token_position = [torch.where(shuffle_indices == token_position[i])[0].item() for i in range(len(token_position))]\n",
    "                token_position = new_token_position\n",
    "            else:\n",
    "                # 找到 cls token 在 shuffle 之后的新位置\n",
    "                token_position = torch.where(shuffle_indices == token_position)[0].item()\n",
    "\n",
    "            if isinstance(token_position, list):\n",
    "                print(\"new value: \", x[0, token_position[0], 0], x[0, token_position[1], 0])\n",
    "            else:\n",
    "                print(\"new value: \", x[0, token_position, 0])\n",
    "            print(\"new token_position: \", token_position)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if_flip_img_sequences = False\n",
    "        if self.flip_img_sequences_ratio > 0 and (self.flip_img_sequences_ratio - random.random()) > 1e-5:\n",
    "            x = x.flip([1])\n",
    "            if_flip_img_sequences = True\n",
    "\n",
    "        # mamba impl\n",
    "        residual = None\n",
    "        hidden_states = x\n",
    "        if not self.if_bidirectional:\n",
    "            for layer in self.layers:\n",
    "\n",
    "                if if_flip_img_sequences and self.if_rope:\n",
    "                    hidden_states = hidden_states.flip([1])\n",
    "                    if residual is not None:\n",
    "                        residual = residual.flip([1])\n",
    "\n",
    "                # rope about\n",
    "                if self.if_rope:\n",
    "                    hidden_states = self.rope(hidden_states)\n",
    "                    if residual is not None and self.if_rope_residual:\n",
    "                        residual = self.rope(residual)\n",
    "\n",
    "                if if_flip_img_sequences and self.if_rope:\n",
    "                    hidden_states = hidden_states.flip([1])\n",
    "                    if residual is not None:\n",
    "                        residual = residual.flip([1])\n",
    "\n",
    "                hidden_states, residual = layer(\n",
    "                    hidden_states, residual, inference_params=inference_params\n",
    "                )\n",
    "        else:\n",
    "            # get two layers in a single for-loop\n",
    "            for i in range(len(self.layers) // 2):\n",
    "                if self.if_rope:\n",
    "                    hidden_states = self.rope(hidden_states)\n",
    "                    if residual is not None and self.if_rope_residual:\n",
    "                        residual = self.rope(residual)\n",
    "\n",
    "                hidden_states_f, residual_f = self.layers[i * 2](\n",
    "                    hidden_states, residual, inference_params=inference_params\n",
    "                )\n",
    "                hidden_states_b, residual_b = self.layers[i * 2 + 1](\n",
    "                    hidden_states.flip([1]), None if residual == None else residual.flip([1]), inference_params=inference_params\n",
    "                )\n",
    "                hidden_states = hidden_states_f + hidden_states_b.flip([1])\n",
    "                residual = residual_f + residual_b.flip([1])\n",
    "\n",
    "        if not self.fused_add_norm:\n",
    "            if residual is None:\n",
    "                residual = hidden_states\n",
    "            else:\n",
    "                residual = residual + self.drop_path(hidden_states)\n",
    "            hidden_states = self.norm_f(residual.to(dtype=self.norm_f.weight.dtype))\n",
    "        else:\n",
    "            # Set prenorm=False here since we don't need the residual\n",
    "            fused_add_norm_fn = rms_norm_fn if isinstance(self.norm_f, RMSNorm) else layer_norm_fn\n",
    "            hidden_states = fused_add_norm_fn(\n",
    "                self.drop_path(hidden_states),\n",
    "                self.norm_f.weight,\n",
    "                self.norm_f.bias,\n",
    "                eps=self.norm_f.eps,\n",
    "                residual=residual,\n",
    "                prenorm=False,\n",
    "                residual_in_fp32=self.residual_in_fp32,\n",
    "            )\n",
    "\n",
    "        # return only cls token if it exists\n",
    "        if self.if_cls_token:\n",
    "            if self.use_double_cls_token:\n",
    "                return (hidden_states[:, token_position[0], :] + hidden_states[:, token_position[1], :]) / 2\n",
    "            else:\n",
    "                if self.use_middle_cls_token:\n",
    "                    return hidden_states[:, token_position, :]\n",
    "                elif if_random_cls_token_position:\n",
    "                    return hidden_states[:, token_position, :]\n",
    "                else:\n",
    "                    return hidden_states[:, token_position, :]\n",
    "\n",
    "        if self.final_pool_type == 'none':\n",
    "            return hidden_states[:, -1, :]\n",
    "        elif self.final_pool_type == 'mean':\n",
    "            return hidden_states.mean(dim=1)\n",
    "        elif self.final_pool_type == 'max':\n",
    "            return hidden_states\n",
    "        elif self.final_pool_type == 'all':\n",
    "            return hidden_states\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, x, return_features=False, inference_params=None, if_random_cls_token_position=False, if_random_token_rank=False):\n",
    "        x = self.forward_features(x, inference_params, if_random_cls_token_position=if_random_cls_token_position, if_random_token_rank=if_random_token_rank)\n",
    "        if return_features:\n",
    "            return x\n",
    "        x = self.head(x)\n",
    "        if self.final_pool_type == 'max':\n",
    "            x = x.max(dim=1)[0]\n",
    "        return x\n",
    "\n",
    "\n",
    "@register_model\n",
    "def vim_tiny_patch16_224_bimambav2_final_pool_mean_abs_pos_embed_with_midclstok_div2(pretrained=False, **kwargs):\n",
    "    model = VisionMamba(\n",
    "        patch_size=16, embed_dim=192, depth=24, rms_norm=True, residual_in_fp32=True, fused_add_norm=True, final_pool_type='mean', if_abs_pos_embed=True, if_rope=False, if_rope_residual=False, bimamba_type=\"v2\", if_cls_token=True, if_divide_out=True, use_middle_cls_token=True, **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    if pretrained:\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url=\"to.do\",\n",
    "            map_location=\"cpu\", check_hash=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "@register_model\n",
    "def vim_tiny_patch16_stride8_224_bimambav2_final_pool_mean_abs_pos_embed_with_midclstok_div2(pretrained=False, **kwargs):\n",
    "    model = VisionMamba(\n",
    "        patch_size=16, stride=8, embed_dim=192, depth=24, rms_norm=True, residual_in_fp32=True, fused_add_norm=True, final_pool_type='mean', if_abs_pos_embed=True, if_rope=False, if_rope_residual=False, bimamba_type=\"v2\", if_cls_token=True, if_divide_out=True, use_middle_cls_token=True, **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    if pretrained:\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url=\"to.do\",\n",
    "            map_location=\"cpu\", check_hash=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "@register_model\n",
    "def vim_small_patch16_224_bimambav2_final_pool_mean_abs_pos_embed_with_midclstok_div2(pretrained=False, **kwargs):\n",
    "    model = VisionMamba(\n",
    "        patch_size=16, embed_dim=384, depth=24, rms_norm=True, residual_in_fp32=True, fused_add_norm=True, final_pool_type='mean', if_abs_pos_embed=True, if_rope=False, if_rope_residual=False, bimamba_type=\"v2\", if_cls_token=True, if_divide_out=True, use_middle_cls_token=True, **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    if pretrained:\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url=\"to.do\",\n",
    "            map_location=\"cpu\", check_hash=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "@register_model\n",
    "def vim_small_patch16_stride8_224_bimambav2_final_pool_mean_abs_pos_embed_with_midclstok_div2(pretrained=False, **kwargs):\n",
    "    model = VisionMamba(\n",
    "        patch_size=16, stride=8, embed_dim=384, depth=24, rms_norm=True, residual_in_fp32=True, fused_add_norm=True, final_pool_type='mean', if_abs_pos_embed=True, if_rope=False, if_rope_residual=False, bimamba_type=\"v2\", if_cls_token=True, if_divide_out=True, use_middle_cls_token=True, **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    if pretrained:\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url=\"to.do\",\n",
    "            map_location=\"cpu\", check_hash=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "    \n",
    "@register_model\n",
    "def vim_base_patch16_224_bimambav2_final_pool_mean_abs_pos_embed_with_middle_cls_token_div2(pretrained=False, **kwargs):\n",
    "    model = VisionMamba(\n",
    "        patch_size=16, embed_dim=768, d_state=16, depth=24, rms_norm=True, residual_in_fp32=True, fused_add_norm=True, final_pool_type='mean', if_abs_pos_embed=True, if_rope=False, if_rope_residual=False, bimamba_type=\"v2\", if_cls_token=True, if_devide_out=True, use_middle_cls_token=True, **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    if pretrained:\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url=\"to.do\",\n",
    "            map_location=\"cpu\", check_hash=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mamba_ssm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/ss6928/ssast/Vim/vim/mamba-1p1p1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# from models_mamba import VisionMamba\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmamba_ssm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtriton\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayernorm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RMSNorm, layer_norm_fn, rms_norm_fn\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# from models_mamba import VisionMamba\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmamba_ssm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtriton\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayernorm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RMSNorm, layer_norm_fn, rms_norm_fn\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mamba_ssm'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Siavash Shams\n",
    "Date: 4/10/2024\n",
    "\n",
    "This script contains the implementation of the AMBAModel and ASTModel for audio processing tasks.\n",
    "The ASTModel is adapted from Yuan Gong's code.\n",
    "\n",
    "\"\"\"\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "from timm.models.layers import trunc_normal_\n",
    "import timm\n",
    "import numpy as np\n",
    "from timm.models.layers import to_2tuple\n",
    "from random import randrange\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "sys.path.append('/home/ss6928/ssast/Vim')\n",
    "sys.path.append('/home/ss6928/ssast/Vim/vim')\n",
    "sys.path.append('/home/ss6928/ssast/Vim/vim/mamba-1p1p1')\n",
    "\n",
    "# from models_mamba import VisionMamba\n",
    "from mamba_ssm.ops.triton.layernorm import RMSNorm, layer_norm_fn, rms_norm_fn\n",
    "\n",
    "try:\n",
    "    # from models_mamba import VisionMamba\n",
    "    from mamba_ssm.ops.triton.layernorm import RMSNorm, layer_norm_fn, rms_norm_fn\n",
    "    \n",
    "except ImportError:\n",
    "    RMSNorm, layer_norm_fn, rms_norm_fn = None, None, None\n",
    "    \n",
    "    \n",
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\" Image to Patch Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "def get_sinusoid_encoding(n_position, d_hid):\n",
    "    ''' Sinusoid position encoding table '''\n",
    "\n",
    "    def get_position_angle_vec(position):\n",
    "        return [position / np.power(10000, 2 * (hid_j // 2) / d_hid) for hid_j in range(d_hid)]\n",
    "\n",
    "    sinusoid_table = np.array([get_position_angle_vec(pos_i) for pos_i in range(n_position)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "\n",
    "    return torch.FloatTensor(sinusoid_table).unsqueeze(0)\n",
    "\n",
    "class AMBAModel(nn.Module):\n",
    "    def __init__(self, label_dim=527,\n",
    "                 fshape=128, tshape=2, fstride=128, tstride=2,\n",
    "                 input_fdim=128, input_tdim=1024, model_size='base',\n",
    "                 pretrain_stage=True, load_pretrained_mdl_path=None, vision_mamba_config=None):\n",
    "        \n",
    "        print(\"Vision Mamba Config:\", vision_mamba_config)\n",
    "        super(AMBAModel, self).__init__()\n",
    "        #assert timm.__version__ == '0.4.5', 'Please use timm == 0.4.5, the code might not be compatible with newer versions.'\n",
    "\n",
    "        # override timm input shape restriction\n",
    "        timm.models.vision_transformer.PatchEmbed = PatchEmbed\n",
    "\n",
    "        # pretrain the AMBA models\n",
    "        if pretrain_stage == True:\n",
    "            if load_pretrained_mdl_path != None:\n",
    "                raise ValueError('Setting load_pretrained_mdl_path at pretraining stage is useless, pretraining is always from scratch, please change it to None.')\n",
    "            if fstride != fshape or tstride != tshape:\n",
    "                raise ValueError('fstride != fshape or tstride != tshape, they must be same at the pretraining stage, patch split overlapping is not supported.')\n",
    "\n",
    "            \n",
    "            default_vision_mamba_config = {\n",
    "            'img_size': (128, 1024),\n",
    "            'patch_size': 16,\n",
    "            'stride': 8,\n",
    "            'embed_dim': 768,\n",
    "            'depth': 24,\n",
    "            'rms_norm': True,\n",
    "            'residual_in_fp32': True,\n",
    "            'fused_add_norm': True,\n",
    "            'final_pool_type': 'mean',\n",
    "            'if_abs_pos_embed': True,\n",
    "            'if_rope': False,\n",
    "            'if_rope_residual': False,\n",
    "            'bimamba_type': \"v2\",\n",
    "            'if_cls_token': True,\n",
    "            'if_devide_out': True,\n",
    "            'use_middle_cls_token': True,\n",
    "        }\n",
    "            \n",
    "            \n",
    "            combined_vision_mamba_config = {**default_vision_mamba_config, **vision_mamba_config}\n",
    "            # Replace self.v with MambaBlocksSequential\n",
    "            print(\"combined_vision_mamba_config\",combined_vision_mamba_config)\n",
    "            self.v = VisionMamba(**combined_vision_mamba_config)\n",
    "\n",
    "            self.cls_token_num = 1\n",
    "            self.original_num_patches = self.v.patch_embed.num_patches\n",
    "            self.oringal_hw = int(self.original_num_patches ** 0.5)\n",
    "            self.original_embedding_dim = self.v.pos_embed.shape[2]\n",
    "\n",
    "            # SSL Pretraining Code\n",
    "            self.softmax = nn.Softmax(dim=-1)\n",
    "            self.lsoftmax = nn.LogSoftmax(dim=-1)\n",
    "            self.fshape, self.tshape = fshape, tshape\n",
    "            self.fstride, self.tstride = fstride, tstride\n",
    "            self.input_fdim, self.input_tdim = input_fdim, input_tdim\n",
    "            # this is a trick to make state_dict to track pretraining input_fdim and input_tdim and save them by using torch.save\n",
    "            self.p_input_fdim, self.p_input_tdim = nn.Parameter(torch.tensor(input_fdim), requires_grad=False), nn.Parameter(torch.tensor(input_tdim), requires_grad=False)\n",
    "\n",
    "            self.cpredlayer = nn.Sequential(nn.Linear(self.original_embedding_dim, self.original_embedding_dim), nn.ReLU(), nn.Linear(self.original_embedding_dim, 256))\n",
    "            # masked patch reconstruction (generative objective) layer\n",
    "            self.gpredlayer = nn.Sequential(nn.Linear(self.original_embedding_dim, self.original_embedding_dim), nn.ReLU(), nn.Linear(self.original_embedding_dim, 256))\n",
    "            self.unfold = torch.nn.Unfold(kernel_size=(fshape, tshape), stride=(fstride, tstride))\n",
    "\n",
    "            # we use learnable mask embedding (follow the BEIT paper), but using a fixed mask embedding (e.g., 0) leads to same performance.\n",
    "            self.mask_embed = nn.Parameter(torch.zeros([1, 1, self.original_embedding_dim]))\n",
    "            self.mask_embed = torch.nn.init.xavier_normal_(self.mask_embed)\n",
    "\n",
    "            # get the intermediate shape\n",
    "            self.p_f_dim, self.p_t_dim = self.get_shape(fstride, tstride, input_fdim, input_tdim, fshape, tshape)\n",
    "            num_patches = self.p_f_dim * self.p_t_dim\n",
    "            self.num_patches = num_patches\n",
    "            self.v.patch_embed.num_patches = num_patches\n",
    "            print('pretraining patch split stride: frequency={:d}, time={:d}'.format(fstride, tstride))\n",
    "            print('pretraining patch shape: frequency={:d}, time={:d}'.format(fshape, tshape))\n",
    "            print('pretraining patch array dimension: frequency={:d}, time={:d}'.format(self.p_f_dim, self.p_t_dim))\n",
    "            print('pretraining number of patches={:d}'.format(num_patches))\n",
    "\n",
    "            # the linear patch projection layer, use 1 channel for spectrogram rather than the original 3 channels for RGB images.\n",
    "            new_proj = torch.nn.Conv2d(1, self.original_embedding_dim, kernel_size=(fshape, tshape), stride=(fstride, tstride))\n",
    "            self.v.patch_embed.proj = new_proj\n",
    "\n",
    "            # use trainable positional embedding\n",
    "            new_pos_embed = nn.Parameter(torch.zeros(1, self.v.patch_embed.num_patches + self.cls_token_num, self.original_embedding_dim))\n",
    "            self.v.pos_embed = new_pos_embed\n",
    "            trunc_normal_(self.v.pos_embed, std=.02)\n",
    "\n",
    "        # use a pretrained models for finetuning\n",
    "        elif pretrain_stage == False:\n",
    "            # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            if load_pretrained_mdl_path == None:\n",
    "                raise ValueError('Please set load_pretrained_mdl_path to load a pretrained models.')\n",
    "            sd = torch.load(load_pretrained_mdl_path, map_location=device)\n",
    "            # get the fshape and tshape, input_fdim and input_tdim in the pretraining stage\n",
    "            try:\n",
    "                p_fshape, p_tshape = sd['module.v.patch_embed.proj.weight'].shape[2], sd['module.v.patch_embed.proj.weight'].shape[3]\n",
    "                p_input_fdim, p_input_tdim = sd['module.p_input_fdim'].item(), sd['module.p_input_tdim'].item()\n",
    "            except:\n",
    "                raise  ValueError('The model loaded is not from a torch.nn.Dataparallel object. Wrap it with torch.nn.Dataparallel and try again.')\n",
    "\n",
    "            print('now load a SSL pretrained models from ' + load_pretrained_mdl_path)\n",
    "            # during pretraining, fstride=fshape and tstride=tshape because no patch overlapping is used\n",
    "            # here, input_fdim and input_tdim should be that used in pretraining, not that in the fine-tuning.\n",
    "            # we need to know input_fdim and input_tdim to do positional embedding cut/interpolation.\n",
    "            # generally it should be better to use same input_fdim during pretraining and finetuning, but input_tdim can be safely different\n",
    "            default_vision_mamba_config = {\n",
    "            'img_size': (128, 1024),\n",
    "            'patch_size': 16,\n",
    "            'stride': 8,\n",
    "            'embed_dim': 768,\n",
    "            'depth': 24,\n",
    "            'rms_norm': True,\n",
    "            'residual_in_fp32': True,\n",
    "            'fused_add_norm': True,\n",
    "            'final_pool_type': 'mean',\n",
    "            'if_abs_pos_embed': True,\n",
    "            'if_rope': False,\n",
    "            'if_rope_residual': False,\n",
    "            'bimamba_type': \"v2\",\n",
    "            'if_cls_token': True,\n",
    "            'if_devide_out': True,\n",
    "            'use_middle_cls_token': True,\n",
    "        }\n",
    "            \n",
    "            \n",
    "            combined_vision_mamba_config = {**default_vision_mamba_config, **vision_mamba_config}\n",
    "            # Replace self.v with MambaBlocksSequential\n",
    "            print(\"combined_vision_mamba_config\",combined_vision_mamba_config)\n",
    "\n",
    "            audio_model = AMBAModel(fstride=p_fshape, tstride=p_tshape, fshape=p_fshape, tshape=p_tshape,\n",
    "                                   input_fdim=p_input_fdim, input_tdim=p_input_tdim, pretrain_stage=True, model_size=model_size, vision_mamba_config=combined_vision_mamba_config)\n",
    "            \n",
    "            audio_model = torch.nn.DataParallel(audio_model)\n",
    "            audio_model.load_state_dict(sd, strict=False)\n",
    "            # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            self.v = audio_model.module.v\n",
    "            self.original_embedding_dim = self.v.pos_embed.shape[2]\n",
    "            self.cls_token_num = audio_model.module.cls_token_num\n",
    "\n",
    "            # mlp head for fine-tuning\n",
    "            self.mlp_head = nn.Sequential(nn.LayerNorm(self.original_embedding_dim),\n",
    "                                          nn.Linear(self.original_embedding_dim, label_dim))\n",
    "\n",
    "            f_dim, t_dim = self.get_shape(fstride, tstride, input_fdim, input_tdim, fshape, tshape)\n",
    "            # patch array dimension during pretraining\n",
    "            p_f_dim, p_t_dim = audio_model.module.p_f_dim, audio_model.module.p_t_dim\n",
    "            num_patches = f_dim * t_dim\n",
    "            p_num_patches = p_f_dim * p_t_dim\n",
    "            self.v.patch_embed.num_patches = num_patches\n",
    "            print('fine-tuning patch split stride: frequncey={:d}, time={:d}'.format(fstride, tstride))\n",
    "            print('fine-tuning number of patches={:d}'.format(num_patches))\n",
    "\n",
    "            # patch shape should be same for pretraining and fine-tuning\n",
    "            if fshape != p_fshape or tshape != p_tshape:\n",
    "                raise ValueError('The patch shape of pretraining and fine-tuning is not consistant, pretraining: f={:d}, t={:d}, finetuning: f={:d}, t={:d}'.format(p_fshape, p_tshape, fshape, tshape))\n",
    "\n",
    "            # patch split stride generally should be different for pretraining and fine-tuning, as patch split overlapping is only used in finetuning\n",
    "            # during pretraining, p_fshape = p_fstride and p_tshape = p_tstride\n",
    "            if fstride != p_fshape or tstride != p_tshape:\n",
    "                # initialize a new patch embedding layer with desired new stride.\n",
    "                new_proj = torch.nn.Conv2d(1, self.original_embedding_dim, kernel_size=(fshape, tshape), stride=(fstride, tstride))\n",
    "                # but the weights of patch embedding layer is still got from the pretrained models\n",
    "                new_proj.weight = torch.nn.Parameter(torch.sum(self.v.patch_embed.proj.weight, dim=1).unsqueeze(1))\n",
    "                new_proj.bias = self.v.patch_embed.proj.bias\n",
    "                self.v.patch_embed.proj = new_proj\n",
    "\n",
    "            new_pos_embed = self.v.pos_embed[:, self.cls_token_num:, :].detach().reshape(1, p_num_patches, self.original_embedding_dim).transpose(1, 2).reshape(1, self.original_embedding_dim, p_f_dim, p_t_dim)\n",
    "            # cut or interpolate the positional embedding\n",
    "            if t_dim < p_t_dim:\n",
    "                new_pos_embed = new_pos_embed[:, :, :, int(p_t_dim/2) - int(t_dim / 2): int(p_t_dim/2) - int(t_dim / 2) + t_dim]\n",
    "            else:\n",
    "                new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(8, t_dim), mode='bilinear')\n",
    "            if f_dim < p_f_dim:\n",
    "                new_pos_embed = new_pos_embed[:, :, int(p_f_dim/2) - int(f_dim / 2): int(p_f_dim/2) - int(f_dim / 2) + t_dim, :]\n",
    "            else:\n",
    "                new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(f_dim, t_dim), mode='bilinear')\n",
    "\n",
    "            new_pos_embed = new_pos_embed.reshape(1, self.original_embedding_dim, num_patches).transpose(1, 2)\n",
    "            self.v.pos_embed = nn.Parameter(torch.cat([self.v.pos_embed[:, :self.cls_token_num, :].detach(), new_pos_embed], dim=1))\n",
    "\n",
    "    # get the shape of intermediate representation.\n",
    "    def get_shape(self, fstride, tstride, input_fdim, input_tdim, fshape, tshape):\n",
    "        test_input = torch.randn(1, 1, input_fdim, input_tdim)\n",
    "        test_proj = nn.Conv2d(1, self.original_embedding_dim, kernel_size=(fshape, tshape), stride=(fstride, tstride))\n",
    "        test_out = test_proj(test_input)\n",
    "        f_dim = test_out.shape[2]\n",
    "        t_dim = test_out.shape[3]\n",
    "        return f_dim, t_dim\n",
    "\n",
    "    # generate mask for 16*16 patch\n",
    "    def gen_maskid_patch(self, sequence_len=512, mask_size=100, cluster=3):\n",
    "        mask_id = []\n",
    "\n",
    "        # randomize clutering factor in [3,6)\n",
    "        cur_clus = randrange(cluster) + 3\n",
    "\n",
    "        while len(list(set(mask_id))) <= mask_size:\n",
    "            start_id = randrange(sequence_len)\n",
    "\n",
    "            # this improves the efficiency, but might change the pretrained model\n",
    "            # while start_id in mask_id:\n",
    "            #     start_id = randrange(sequence_len)\n",
    "\n",
    "            cur_mask = []\n",
    "            for i in range(0, cur_clus):\n",
    "                for j in range(0, cur_clus):\n",
    "                    mask_cand = start_id + self.p_t_dim * i + j\n",
    "                    if mask_cand > 0 and mask_cand < sequence_len:\n",
    "                        cur_mask.append(mask_cand)\n",
    "            mask_id = mask_id + cur_mask\n",
    "        mask_id = list(set(mask_id))[:mask_size]\n",
    "        return torch.tensor(mask_id)\n",
    "\n",
    "    # using cluster for frame masking hurts the performance, so just use the naive random sampling\n",
    "    def gen_maskid_frame(self, sequence_len=512, mask_size=100):\n",
    "        mask_id = random.sample(range(0, sequence_len), mask_size)\n",
    "        return torch.tensor(mask_id)\n",
    "    \n",
    "    def finetuningavgtok_1sec(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.v.patch_embed(x)\n",
    "        if self.cls_token_num == 2:\n",
    "            cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "            dist_token = self.v.dist_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
    "        else:\n",
    "            cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.v.pos_embed\n",
    "        x = self.v.pos_drop(x)\n",
    "        \n",
    "        # mamba impl\n",
    "        residual = None\n",
    "        hidden_states = x\n",
    "        token_position = 0\n",
    "        if not self.v.if_bidirectional:\n",
    "            for layer in self.v.layers:\n",
    "                hidden_states, residual = layer(hidden_states, residual)\n",
    "        else:\n",
    "            for i in range(len(self.v.layers) // 2):\n",
    "                hidden_states_f, residual_f = self.v.layers[i * 2](hidden_states, residual)\n",
    "                hidden_states_b, residual_b = self.v.layers[i * 2 + 1](hidden_states.flip([1]), None if residual is None else residual.flip([1]))\n",
    "                hidden_states = hidden_states_f + hidden_states_b.flip([1])\n",
    "                residual = residual_f + residual_b.flip([1])\n",
    "\n",
    "        if not self.v.fused_add_norm:\n",
    "            if residual is None:\n",
    "                residual = hidden_states\n",
    "            else:\n",
    "                residual = residual + self.v.drop_path(hidden_states)\n",
    "            hidden_states = self.v.norm_f(residual.to(dtype=self.v.norm_f.weight.dtype))\n",
    "        else:\n",
    "            fused_add_norm_fn = rms_norm_fn if isinstance(self.v.norm_f, RMSNorm) else layer_norm_fn\n",
    "            hidden_states = fused_add_norm_fn(\n",
    "                self.v.drop_path(hidden_states),\n",
    "                self.v.norm_f.weight,\n",
    "                self.v.norm_f.bias,\n",
    "                eps=self.v.norm_f.eps,\n",
    "                residual=residual,\n",
    "                prenorm=False,\n",
    "                residual_in_fp32=self.v.residual_in_fp32,\n",
    "            )\n",
    "\n",
    "        x = self.v.norm_f(hidden_states)\n",
    "\n",
    "        # Average output of tokens within each 1-second segment\n",
    "        tokens_per_second = x.shape[1] // 60  \n",
    "        x_averaged = torch.stack([torch.mean(x[:, i * tokens_per_second:(i + 1) * tokens_per_second, :], dim=1) for i in range(60)], dim=1)\n",
    "        x_averaged = self.mlp_head(x_averaged)\n",
    "        return x_averaged\n",
    "\n",
    "    def finetuningavgtok(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.v.patch_embed(x)\n",
    "        if self.cls_token_num == 2:\n",
    "            cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "            dist_token = self.v.dist_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
    "        else:\n",
    "            cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.v.pos_embed\n",
    "        x = self.v.pos_drop(x)\n",
    "        \n",
    "        \n",
    "        # mamba impl\n",
    "        residual = None\n",
    "        hidden_states = x\n",
    "        token_position = 0\n",
    "        if not self.v.if_bidirectional:\n",
    "            for layer in self.v.layers:\n",
    "                \n",
    "                hidden_states, residual = layer(\n",
    "                    hidden_states, residual\n",
    "                )\n",
    "        else:\n",
    "            # get two layers in a single for-loop\n",
    "            for i in range(len(self.v.layers) // 2):\n",
    "\n",
    "                hidden_states_f, residual_f = self.v.layers[i * 2](\n",
    "                    hidden_states, residual\n",
    "                )\n",
    "                hidden_states_b, residual_b = self.v.layers[i * 2 + 1](\n",
    "                    hidden_states.flip([1]), None if residual == None else residual.flip([1])\n",
    "                )\n",
    "                hidden_states = hidden_states_f + hidden_states_b.flip([1])\n",
    "                residual = residual_f + residual_b.flip([1])\n",
    "\n",
    "        if not self.v.fused_add_norm:\n",
    "            if residual is None:\n",
    "                residual = hidden_states\n",
    "            else:\n",
    "                residual = residual + self.v.drop_path(hidden_states)\n",
    "            hidden_states = self.v.norm_f(residual.to(dtype=self.v.norm_f.weight.dtype))\n",
    "        else:\n",
    "            # Set prenorm=False here since we don't need the residual\n",
    "            fused_add_norm_fn = rms_norm_fn if isinstance(self.v.norm_f, RMSNorm) else layer_norm_fn\n",
    "            hidden_states = fused_add_norm_fn(\n",
    "                self.v.drop_path(hidden_states),\n",
    "                self.v.norm_f.weight,\n",
    "                self.v.norm_f.bias,\n",
    "                eps=self.v.norm_f.eps,\n",
    "                residual=residual,\n",
    "                prenorm=False,\n",
    "                residual_in_fp32=self.v.residual_in_fp32,\n",
    "            )\n",
    "\n",
    "        x = self.v.norm_f(hidden_states)\n",
    "\n",
    "        # average output of all tokens except cls token(s)\n",
    "        x = torch.mean(x[:, self.cls_token_num:, :], dim=1)\n",
    "        x = self.mlp_head(x)\n",
    "        return x\n",
    "\n",
    "    def finetuningcls(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.v.patch_embed(x)\n",
    "        if self.cls_token_num == 2:\n",
    "            cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "            dist_token = self.v.dist_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
    "        else:\n",
    "            cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.v.pos_embed\n",
    "        x = self.v.pos_drop(x)\n",
    "        \n",
    "        \n",
    "        # mamba impl\n",
    "        residual = None\n",
    "        hidden_states = x\n",
    "        token_position = 0\n",
    "        if not self.v.if_bidirectional:\n",
    "            for layer in self.v.layers:\n",
    "                \n",
    "                hidden_states, residual = layer(\n",
    "                    hidden_states, residual\n",
    "                )\n",
    "        else:\n",
    "            # get two layers in a single for-loop\n",
    "            for i in range(len(self.v.layers) // 2):\n",
    "\n",
    "                hidden_states_f, residual_f = self.v.layers[i * 2](\n",
    "                    hidden_states, residual\n",
    "                )\n",
    "                hidden_states_b, residual_b = self.v.layers[i * 2 + 1](\n",
    "                    hidden_states.flip([1]), None if residual == None else residual.flip([1])\n",
    "                )\n",
    "                hidden_states = hidden_states_f + hidden_states_b.flip([1])\n",
    "                residual = residual_f + residual_b.flip([1])\n",
    "\n",
    "        if not self.v.fused_add_norm:\n",
    "            if residual is None:\n",
    "                residual = hidden_states\n",
    "            else:\n",
    "                residual = residual + self.v.drop_path(hidden_states)\n",
    "            hidden_states = self.v.norm_f(residual.to(dtype=self.v.norm_f.weight.dtype))\n",
    "        else:\n",
    "            # Set prenorm=False here since we don't need the residual\n",
    "            fused_add_norm_fn = rms_norm_fn if isinstance(self.v.norm_f, RMSNorm) else layer_norm_fn\n",
    "            hidden_states = fused_add_norm_fn(\n",
    "                self.v.drop_path(hidden_states),\n",
    "                self.v.norm_f.weight,\n",
    "                self.v.norm_f.bias,\n",
    "                eps=self.v.norm_f.eps,\n",
    "                residual=residual,\n",
    "                prenorm=False,\n",
    "                residual_in_fp32=self.v.residual_in_fp32,\n",
    "            )\n",
    "\n",
    "       \n",
    "        x = self.v.norm_f(hidden_states)\n",
    "\n",
    "\n",
    "        # if models has two cls tokens (DEIT), average as the clip-level representation\n",
    "        if self.cls_token_num == 2:\n",
    "            x = (x[:, 0] + x[:, 1]) / 2\n",
    "        else:\n",
    "            x = x[:, 0]\n",
    "        x = self.mlp_head(x)\n",
    "        return x\n",
    "\n",
    "    # masked patch pretraining with discriminative objective\n",
    "    def mpc(self, x, mask_patch, cluster, show_mask=False):\n",
    "        input = self.unfold(x).transpose(1, 2)\n",
    "        B = x.shape[0]\n",
    "        # x in shape (batch_size, sequence_len, embedding dim)\n",
    "        x = self.v.patch_embed(x)\n",
    "\n",
    "        # encode the patch\n",
    "        # size 12(batch_size) * 100(#mask_patch) * 768(hidden_dim), prepare to save the true values of masked samples\n",
    "        encode_samples = torch.empty((B, mask_patch, 256), device=x.device, requires_grad=False).float()\n",
    "        # size 12(batch_size) * 100(#mask_patch), index of masked patches\n",
    "        mask_index = torch.empty((B, mask_patch), device=x.device, requires_grad=False).long()\n",
    "        # size 12(batch_size) * 512(sequence_len) * 768(hidden_dim)\n",
    "        mask_dense = torch.ones([x.shape[0], x.shape[1], x.shape[2]], device=x.device)\n",
    "\n",
    "        # for each audio clip in the batch\n",
    "        for i in range(B):\n",
    "            # randomly generate #mask_patch mask indexes without duplicate\n",
    "            if cluster == True:\n",
    "                # use this if you are masking e.g. 16*16 patches\n",
    "                mask_index[i] = self.gen_maskid_patch(self.num_patches, mask_patch)\n",
    "            else:\n",
    "                # use this if you are masking frame, i.e., 128*2 patches\n",
    "                mask_index[i] = self.gen_maskid_frame(self.num_patches, mask_patch)\n",
    "            # copy the masked embeddings, note gradients are stopped in this path\n",
    "            encode_samples[i] = input[i, mask_index[i], :].clone().detach()\n",
    "            # mask the encode samples with 0\n",
    "            mask_dense[i, mask_index[i], :] = 0\n",
    "\n",
    "        # follow BEIT paper, mask with learnable masking embedding, but no performance diff observed compared with masking with 0s.\n",
    "        mask_tokens = self.mask_embed.expand(B, x.shape[1], -1)\n",
    "\n",
    "        # mask the patch\n",
    "        x = x * mask_dense + (1-mask_dense) * mask_tokens\n",
    "\n",
    "        # pass through the Transformer layers\n",
    "        cls_tokens = self.v.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        #dist_token = self.v.dist_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.v.pos_embed\n",
    "        x = self.v.pos_drop(x)\n",
    "    \n",
    "        \n",
    "        # mamba impl\n",
    "        residual = None\n",
    "        hidden_states = x\n",
    "        token_position = 0\n",
    "        if not self.v.if_bidirectional:\n",
    "            for layer in self.v.layers:\n",
    "                \n",
    "                hidden_states, residual = layer(\n",
    "                    hidden_states, residual\n",
    "                )\n",
    "        else:\n",
    "            # get two layers in a single for-loop\n",
    "            for i in range(len(self.v.layers) // 2):\n",
    "\n",
    "                hidden_states_f, residual_f = self.v.layers[i * 2](\n",
    "                    hidden_states, residual\n",
    "                )\n",
    "                hidden_states_b, residual_b = self.v.layers[i * 2 + 1](\n",
    "                    hidden_states.flip([1]), None if residual == None else residual.flip([1])\n",
    "                )\n",
    "                hidden_states = hidden_states_f + hidden_states_b.flip([1])\n",
    "                residual = residual_f + residual_b.flip([1])\n",
    "\n",
    "        if not self.v.fused_add_norm:\n",
    "            if residual is None:\n",
    "                residual = hidden_states\n",
    "            else:\n",
    "                residual = residual + self.v.drop_path(hidden_states)\n",
    "            hidden_states = self.v.norm_f(residual.to(dtype=self.v.norm_f.weight.dtype))\n",
    "        else:\n",
    "            # Set prenorm=False here since we don't need the residual\n",
    "            fused_add_norm_fn = rms_norm_fn if isinstance(self.v.norm_f, RMSNorm) else layer_norm_fn\n",
    "            hidden_states = fused_add_norm_fn(\n",
    "                self.v.drop_path(hidden_states),\n",
    "                self.v.norm_f.weight,\n",
    "                self.v.norm_f.bias,\n",
    "                eps=self.v.norm_f.eps,\n",
    "                residual=residual,\n",
    "                prenorm=False,\n",
    "                residual_in_fp32=self.v.residual_in_fp32,\n",
    "            )\n",
    "\n",
    "        # return only cls token if it exists\n",
    "        \n",
    "        x = self.v.norm_f(hidden_states)\n",
    "        \n",
    "        \n",
    "   \n",
    "        pred = torch.empty((B, mask_patch, 256), device=x.device).float()  # e.g. size 12*100*768\n",
    "        for i in range(B):\n",
    "            #  +2 for indexes because skipping the cls and dis token\n",
    "            # we map the output of transformer (768-dim for base models) to 256-dim patch input space, and then dot product with flattened patch input (also 256-dim) to calculate loss.\n",
    "            # alternatively, you can map the output of transformer to 768-dim patch embedding space, and dot product with patch embedding. Performance-wise they are similar, but map to 256 space is more efficient.\n",
    "            pred[i] = self.cpredlayer(x[i, mask_index[i] + self.cls_token_num, :])\n",
    "\n",
    "        # calculate the NCE loss\n",
    "        nce = torch.tensor(0.0).to(x.device)\n",
    "        correct = torch.tensor(0.0).to(x.device)\n",
    "        for i in np.arange(0, B):\n",
    "            # negative samples are from the same batch\n",
    "            # 8/12/2022: has a difference with equation (1) in the ssast paper but (likely) performance-wise similar, see https://github.com/YuanGongND/ssast/issues/13\n",
    "            total = torch.mm(encode_samples[i], torch.transpose(pred[i], 0, 1))  # e.g. size 100*100\n",
    "            correct += torch.sum(torch.eq(torch.argmax(self.softmax(total), dim=0), torch.arange(0, mask_patch, device=x.device)))  # correct is a tensor\n",
    "            nce += torch.sum(torch.diag(self.lsoftmax(total)))  # nce is a tensor\n",
    "        acc = 1. * correct / (B * mask_patch)\n",
    "        nce = nce / (-1. * B * mask_patch)\n",
    "\n",
    "        # visualize the masked area, for probing test only, set show_mask = False for any training/inference.\n",
    "        if show_mask == False:\n",
    "            return acc, nce\n",
    "        else:\n",
    "            if B > 1:\n",
    "                raise Exception('Currently only support single spectrogram probing test.')\n",
    "\n",
    "            self.mask_correct = torch.nn.Parameter(torch.arange(0, mask_patch), requires_grad=False)\n",
    "\n",
    "            pred = input.clone()  # [B, 512, 256]\n",
    "            masked = input.clone()\n",
    "\n",
    "            for i in range(B):\n",
    "                result = [float(t) * 99 for t in torch.eq(torch.argmax(self.softmax(total), dim=0), self.mask_correct)]\n",
    "                pred[i, mask_index[i], :] = torch.tensor(result).reshape(mask_patch, 1).expand(mask_patch, 256)\n",
    "                masked[i, mask_index[i], :] = 99.0\n",
    "\n",
    "            # print(total)\n",
    "            # print(self.softmax(total))\n",
    "            # print(torch.argmax(self.softmax(total), dim=0))\n",
    "            # print(self.mask_correct)\n",
    "            # print(torch.eq(torch.argmax(self.softmax(total), dim=0), self.mask_correct))\n",
    "            # print([float(t)*99 for t in torch.eq(torch.argmax(self.softmax(total), dim=0), self.mask_correct)])\n",
    "\n",
    "            fold = torch.nn.Fold(output_size=([self.input_fdim, self.input_tdim]), kernel_size=(self.fshape, self.tshape), stride=(self.fstride, self.tstride))\n",
    "            pred = fold(pred.transpose(1, 2))\n",
    "            masked = fold(masked.transpose(1, 2))\n",
    "\n",
    "            return pred, masked\n",
    "\n",
    "        \n",
    "    # # masked patch pretraining with generative objective\n",
    "    def mpg(self, input, mask_patch, cluster):\n",
    "        \n",
    "        B = input.shape[0]\n",
    "        x = self.v.patch_embed(input)\n",
    "        input = self.unfold(input).transpose(1, 2)\n",
    "\n",
    "        # size 12(batch_size) * 100(#mask_patch), index of masked patches\n",
    "        mask_index = torch.empty((B, mask_patch), device=x.device, requires_grad=False).long()\n",
    "        # size 12(batch_size) * 512(sequence_len) * 768(hidden_dim)\n",
    "        mask_dense = torch.ones([x.shape[0], x.shape[1], x.shape[2]], device=x.device)\n",
    "        for i in range(B):\n",
    "            # randomly generate #mask_patch mask indexes without duplicate\n",
    "            if cluster == True:\n",
    "                # use this if you are masking e.g. 16*16 patches\n",
    "                mask_index[i] = self.gen_maskid_patch(self.num_patches, mask_patch)\n",
    "            else:\n",
    "                # use this if you are masking frame, i.e., 128*2 patches\n",
    "                mask_index[i] = self.gen_maskid_frame(self.num_patches, mask_patch)\n",
    "            mask_dense[i, mask_index[i], :] = 0\n",
    "\n",
    "        mask_tokens = self.mask_embed.expand(B, x.shape[1], -1)\n",
    "\n",
    "        # follow BEIT paper, mask with learnable masking embedding, but no performance diff observed compared with masking with 0s.\n",
    "        x = x * mask_dense + (1-mask_dense) * mask_tokens\n",
    "\n",
    "        # go through the Transformer layers\n",
    "        cls_tokens = self.v.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        #dist_token = self.v.dist_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.v.pos_embed\n",
    "        x = self.v.pos_drop(x)\n",
    "        \n",
    "        # mamba impl\n",
    "        residual = None\n",
    "        hidden_states = x\n",
    "        token_position = 0\n",
    "        if not self.v.if_bidirectional:\n",
    "            for layer in self.v.layers:\n",
    "                \n",
    "                hidden_states, residual = layer(\n",
    "                    hidden_states, residual\n",
    "                )\n",
    "        else:\n",
    "            # get two layers in a single for-loop\n",
    "            for i in range(len(self.v.layers) // 2):\n",
    "\n",
    "                hidden_states_f, residual_f = self.v.layers[i * 2](\n",
    "                    hidden_states, residual\n",
    "                )\n",
    "                hidden_states_b, residual_b = self.v.layers[i * 2 + 1](\n",
    "                    hidden_states.flip([1]), None if residual == None else residual.flip([1])\n",
    "                )\n",
    "                hidden_states = hidden_states_f + hidden_states_b.flip([1])\n",
    "                residual = residual_f + residual_b.flip([1])\n",
    "\n",
    "        if not self.v.fused_add_norm:\n",
    "            if residual is None:\n",
    "                residual = hidden_states\n",
    "            else:\n",
    "                residual = residual + self.v.drop_path(hidden_states)\n",
    "            hidden_states = self.v.norm_f(residual.to(dtype=self.v.norm_f.weight.dtype))\n",
    "        else:\n",
    "            # Set prenorm=False here since we don't need the residual\n",
    "            fused_add_norm_fn = rms_norm_fn if isinstance(self.v.norm_f, RMSNorm) else layer_norm_fn\n",
    "            hidden_states = fused_add_norm_fn(\n",
    "                self.v.drop_path(hidden_states),\n",
    "                self.v.norm_f.weight,\n",
    "                self.v.norm_f.bias,\n",
    "                eps=self.v.norm_f.eps,\n",
    "                residual=residual,\n",
    "                prenorm=False,\n",
    "                residual_in_fp32=self.v.residual_in_fp32,\n",
    "            )\n",
    "\n",
    "        \n",
    "        x = self.v.norm_f(hidden_states)\n",
    "        \n",
    "        pred = torch.empty((B, mask_patch, self.fshape * self.tshape), device=x.device).float()  # e.g. size 12*100*256\n",
    "        target = torch.empty((B, mask_patch, self.fshape * self.tshape), device=x.device).float() # e.g. size 12*100*256\n",
    "\n",
    "        for i in range(B):\n",
    "            #  +2 for indexes because cls and dis token\n",
    "            pred[i] = self.gpredlayer(x[i, mask_index[i] + self.cls_token_num, :])\n",
    "            target[i] = input[i, mask_index[i], :]\n",
    "\n",
    "        # calculate the MSE loss\n",
    "        mse = torch.mean((pred - target) ** 2)\n",
    "\n",
    "        return mse\n",
    "        \n",
    "     \n",
    "    def forward(self, x, task, cluster=True, mask_patch=400):\n",
    "        # expect input x = (batch_size, time_frame_num, frequency_bins), e.g., (12, 1024, 128)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = x.transpose(2, 3)\n",
    "\n",
    "        # finetuning (ft), use the mean of all token (patch) output as clip-level representation.\n",
    "        # this is default for SSAMBA fine-tuning as during pretraining, supervision signal is given to each token, not the [cls] token\n",
    "        if task == 'ft_avgtok':\n",
    "            return self.finetuningavgtok(x)\n",
    "        elif task == 'ft_avgtok_1sec':\n",
    "            return self.finetuningavgtok_1sec(x)\n",
    "        # alternatively, use the [cls] token output as clip-level representation.\n",
    "        elif task == 'ft_cls':\n",
    "            return self.finetuningcls(x)\n",
    "        # pretraining, masked patch classification (discriminative objective)\n",
    "        elif task == 'pretrain_mpc':\n",
    "            return self.mpc(x, mask_patch=mask_patch, cluster=cluster)\n",
    "        # pretraining, masked patch reconstruction (generative objective)\n",
    "        elif task == 'pretrain_mpg':\n",
    "            return self.mpg(x, mask_patch=mask_patch, cluster=cluster)\n",
    "        elif task == 'visualize_mask':\n",
    "            return self.mpc(x, mask_patch=mask_patch, cluster=cluster, show_mask=True)\n",
    "        else:\n",
    "            raise Exception('Task unrecognized.')\n",
    "\n",
    "            \n",
    "class ASTModel(nn.Module):\n",
    "    def __init__(self, label_dim=527,\n",
    "                 fshape=128, tshape=2, fstride=128, tstride=2,\n",
    "                 input_fdim=128, input_tdim=1024, model_size='base_nokd',\n",
    "                 pretrain_stage=True, load_pretrained_mdl_path=None):\n",
    "\n",
    "        super(ASTModel, self).__init__()\n",
    "        assert timm.__version__ == '0.4.5', 'Please use timm == 0.4.5, the code might not be compatible with newer versions.'\n",
    "\n",
    "        # override timm input shape restriction\n",
    "        timm.models.vision_transformer.PatchEmbed = PatchEmbed\n",
    "\n",
    "        # pretrain the AST models\n",
    "        if pretrain_stage == True:\n",
    "            if load_pretrained_mdl_path != None:\n",
    "                raise ValueError('Setting load_pretrained_mdl_path at pretraining stage is useless, pretraining is always from scratch, please change it to None.')\n",
    "            if fstride != fshape or tstride != tshape:\n",
    "                raise ValueError('fstride != fshape or tstride != tshape, they must be same at the pretraining stage, patch split overlapping is not supported.')\n",
    "\n",
    "            # if AudioSet pretraining is not used (but ImageNet pretraining may still apply)\n",
    "            if model_size == 'tiny':\n",
    "                self.v = timm.create_model('vit_deit_tiny_distilled_patch16_224', pretrained=False)\n",
    "                self.heads, self.depth = 3, 12\n",
    "                self.cls_token_num = 2\n",
    "            elif model_size == 'small':\n",
    "                self.v = timm.create_model('vit_deit_small_distilled_patch16_224', pretrained=False)\n",
    "                self.heads, self.depth = 6, 12\n",
    "                self.cls_token_num = 2\n",
    "            elif model_size == 'base':\n",
    "                self.v = timm.create_model('vit_deit_base_distilled_patch16_384', pretrained=False)\n",
    "                self.heads, self.depth = 12, 12\n",
    "                self.cls_token_num = 2\n",
    "            elif model_size == 'base_nokd':\n",
    "                self.v = timm.create_model('vit_deit_base_patch16_384', pretrained=False)\n",
    "                self.heads, self.depth = 12, 12\n",
    "                self.cls_token_num = 1\n",
    "            else:\n",
    "                raise Exception('Model size must be one of tiny, small, base, base_nokd')\n",
    "\n",
    "            self.original_num_patches = self.v.patch_embed.num_patches\n",
    "            self.oringal_hw = int(self.original_num_patches ** 0.5)\n",
    "            self.original_embedding_dim = self.v.pos_embed.shape[2]\n",
    "\n",
    "            # SSL Pretraining Code\n",
    "            self.softmax = nn.Softmax(dim=-1)\n",
    "            self.lsoftmax = nn.LogSoftmax(dim=-1)\n",
    "            self.fshape, self.tshape = fshape, tshape\n",
    "            self.fstride, self.tstride = fstride, tstride\n",
    "            self.input_fdim, self.input_tdim = input_fdim, input_tdim\n",
    "            # this is a trick to make state_dict to track pretraining input_fdim and input_tdim and save them by using torch.save\n",
    "            self.p_input_fdim, self.p_input_tdim = nn.Parameter(torch.tensor(input_fdim), requires_grad=False), nn.Parameter(torch.tensor(input_tdim), requires_grad=False)\n",
    "\n",
    "            # masked patch classification (discriminative objective) layer\n",
    "            # we use two layers for pretext task, but using a single layer has similar performance.\n",
    "            # we map the output of transformer (768-dim for base models) to 256-dim patch input space, and then dot product with flattened patch input (also 256-dim) to calculate loss.\n",
    "            # alternatively, you can map the output of transformer to 768-dim patch embedding space, and dot product with patch embedding. Performance-wise they are similar, but map to 256 space is more efficient.\n",
    "            self.cpredlayer = nn.Sequential(nn.Linear(self.original_embedding_dim, self.original_embedding_dim), nn.ReLU(), nn.Linear(self.original_embedding_dim, 256))\n",
    "            # masked patch reconstruction (generative objective) layer\n",
    "            self.gpredlayer = nn.Sequential(nn.Linear(self.original_embedding_dim, self.original_embedding_dim), nn.ReLU(), nn.Linear(self.original_embedding_dim, 256))\n",
    "            self.unfold = torch.nn.Unfold(kernel_size=(fshape, tshape), stride=(fstride, tstride))\n",
    "\n",
    "            # we use learnable mask embedding (follow the BEIT paper), but using a fixed mask embedding (e.g., 0) leads to same performance.\n",
    "            self.mask_embed = nn.Parameter(torch.zeros([1, 1, self.original_embedding_dim]))\n",
    "            self.mask_embed = torch.nn.init.xavier_normal_(self.mask_embed)\n",
    "\n",
    "            # get the intermediate shape\n",
    "            self.p_f_dim, self.p_t_dim = self.get_shape(fstride, tstride, input_fdim, input_tdim, fshape, tshape)\n",
    "            num_patches = self.p_f_dim * self.p_t_dim\n",
    "            self.num_patches = num_patches\n",
    "            self.v.patch_embed.num_patches = num_patches\n",
    "            print('pretraining patch split stride: frequency={:d}, time={:d}'.format(fstride, tstride))\n",
    "            print('pretraining patch shape: frequency={:d}, time={:d}'.format(fshape, tshape))\n",
    "            print('pretraining patch array dimension: frequency={:d}, time={:d}'.format(self.p_f_dim, self.p_t_dim))\n",
    "            print('pretraining number of patches={:d}'.format(num_patches))\n",
    "\n",
    "            # the linear patch projection layer, use 1 channel for spectrogram rather than the original 3 channels for RGB images.\n",
    "            new_proj = torch.nn.Conv2d(1, self.original_embedding_dim, kernel_size=(fshape, tshape), stride=(fstride, tstride))\n",
    "            self.v.patch_embed.proj = new_proj\n",
    "\n",
    "            # use trainable positional embedding\n",
    "            new_pos_embed = nn.Parameter(torch.zeros(1, self.v.patch_embed.num_patches + self.cls_token_num, self.original_embedding_dim))\n",
    "            self.v.pos_embed = new_pos_embed\n",
    "            trunc_normal_(self.v.pos_embed, std=.02)\n",
    "\n",
    "        # use a pretrained models for finetuning\n",
    "        elif pretrain_stage == False:\n",
    "            # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            if load_pretrained_mdl_path == None:\n",
    "                raise ValueError('Please set load_pretrained_mdl_path to load a pretrained models.')\n",
    "            sd = torch.load(load_pretrained_mdl_path, map_location=device)\n",
    "            # get the fshape and tshape, input_fdim and input_tdim in the pretraining stage\n",
    "            try:\n",
    "                p_fshape, p_tshape = sd['module.v.patch_embed.proj.weight'].shape[2], sd['module.v.patch_embed.proj.weight'].shape[3]\n",
    "                p_input_fdim, p_input_tdim = sd['module.p_input_fdim'].item(), sd['module.p_input_tdim'].item()\n",
    "            except:\n",
    "                raise  ValueError('The model loaded is not from a torch.nn.Dataparallel object. Wrap it with torch.nn.Dataparallel and try again.')\n",
    "\n",
    "            print('now load a SSL pretrained models from ' + load_pretrained_mdl_path)\n",
    "            # during pretraining, fstride=fshape and tstride=tshape because no patch overlapping is used\n",
    "            # here, input_fdim and input_tdim should be that used in pretraining, not that in the fine-tuning.\n",
    "            # we need to know input_fdim and input_tdim to do positional embedding cut/interpolation.\n",
    "            # generally it should be better to use same input_fdim during pretraining and finetuning, but input_tdim can be safely different\n",
    "            audio_model = ASTModel(fstride=p_fshape, tstride=p_tshape, fshape=p_fshape, tshape=p_tshape,\n",
    "                                   input_fdim=p_input_fdim, input_tdim=p_input_tdim, pretrain_stage=True, model_size=model_size)\n",
    "            audio_model = torch.nn.DataParallel(audio_model)\n",
    "            audio_model.load_state_dict(sd, strict=False)\n",
    "\n",
    "            self.v = audio_model.module.v\n",
    "            self.original_embedding_dim = self.v.pos_embed.shape[2]\n",
    "            self.cls_token_num = audio_model.module.cls_token_num\n",
    "\n",
    "            # mlp head for fine-tuning\n",
    "            self.mlp_head = nn.Sequential(nn.LayerNorm(self.original_embedding_dim),\n",
    "                                          nn.Linear(self.original_embedding_dim, label_dim))\n",
    "\n",
    "            f_dim, t_dim = self.get_shape(fstride, tstride, input_fdim, input_tdim, fshape, tshape)\n",
    "            # patch array dimension during pretraining\n",
    "            p_f_dim, p_t_dim = audio_model.module.p_f_dim, audio_model.module.p_t_dim\n",
    "            num_patches = f_dim * t_dim\n",
    "            p_num_patches = p_f_dim * p_t_dim\n",
    "            self.v.patch_embed.num_patches = num_patches\n",
    "            print('fine-tuning patch split stride: frequncey={:d}, time={:d}'.format(fstride, tstride))\n",
    "            print('fine-tuning number of patches={:d}'.format(num_patches))\n",
    "\n",
    "            # patch shape should be same for pretraining and fine-tuning\n",
    "            if fshape != p_fshape or tshape != p_tshape:\n",
    "                raise ValueError('The patch shape of pretraining and fine-tuning is not consistant, pretraining: f={:d}, t={:d}, finetuning: f={:d}, t={:d}'.format(p_fshape, p_tshape, fshape, tshape))\n",
    "\n",
    "            # patch split stride generally should be different for pretraining and fine-tuning, as patch split overlapping is only used in finetuning\n",
    "            # during pretraining, p_fshape = p_fstride and p_tshape = p_tstride\n",
    "            if fstride != p_fshape or tstride != p_tshape:\n",
    "                # initialize a new patch embedding layer with desired new stride.\n",
    "                new_proj = torch.nn.Conv2d(1, self.original_embedding_dim, kernel_size=(fshape, tshape), stride=(fstride, tstride))\n",
    "                # but the weights of patch embedding layer is still got from the pretrained models\n",
    "                new_proj.weight = torch.nn.Parameter(torch.sum(self.v.patch_embed.proj.weight, dim=1).unsqueeze(1))\n",
    "                new_proj.bias = self.v.patch_embed.proj.bias\n",
    "                self.v.patch_embed.proj = new_proj\n",
    "\n",
    "            new_pos_embed = self.v.pos_embed[:, self.cls_token_num:, :].detach().reshape(1, p_num_patches, self.original_embedding_dim).transpose(1, 2).reshape(1, self.original_embedding_dim, p_f_dim, p_t_dim)\n",
    "            # cut or interpolate the positional embedding\n",
    "            if t_dim < p_t_dim:\n",
    "                new_pos_embed = new_pos_embed[:, :, :, int(p_t_dim/2) - int(t_dim / 2): int(p_t_dim/2) - int(t_dim / 2) + t_dim]\n",
    "            else:\n",
    "                new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(8, t_dim), mode='bilinear')\n",
    "            if f_dim < p_f_dim:\n",
    "                new_pos_embed = new_pos_embed[:, :, int(p_f_dim/2) - int(f_dim / 2): int(p_f_dim/2) - int(f_dim / 2) + t_dim, :]\n",
    "            else:\n",
    "                new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(f_dim, t_dim), mode='bilinear')\n",
    "\n",
    "            new_pos_embed = new_pos_embed.reshape(1, self.original_embedding_dim, num_patches).transpose(1, 2)\n",
    "            self.v.pos_embed = nn.Parameter(torch.cat([self.v.pos_embed[:, :self.cls_token_num, :].detach(), new_pos_embed], dim=1))\n",
    "\n",
    "    # get the shape of intermediate representation.\n",
    "    def get_shape(self, fstride, tstride, input_fdim, input_tdim, fshape, tshape):\n",
    "        test_input = torch.randn(1, 1, input_fdim, input_tdim)\n",
    "        test_proj = nn.Conv2d(1, self.original_embedding_dim, kernel_size=(fshape, tshape), stride=(fstride, tstride))\n",
    "        test_out = test_proj(test_input)\n",
    "        f_dim = test_out.shape[2]\n",
    "        t_dim = test_out.shape[3]\n",
    "        return f_dim, t_dim\n",
    "\n",
    "    # generate mask for 16*16 patch\n",
    "    def gen_maskid_patch(self, sequence_len=512, mask_size=100, cluster=3):\n",
    "        mask_id = []\n",
    "\n",
    "        # randomize clutering factor in [3,6)\n",
    "        cur_clus = randrange(cluster) + 3\n",
    "\n",
    "        while len(list(set(mask_id))) <= mask_size:\n",
    "            start_id = randrange(sequence_len)\n",
    "\n",
    "            # this improves the efficiency, but might change the pretrained model\n",
    "            # while start_id in mask_id:\n",
    "            #     start_id = randrange(sequence_len)\n",
    "\n",
    "            cur_mask = []\n",
    "            for i in range(0, cur_clus):\n",
    "                for j in range(0, cur_clus):\n",
    "                    mask_cand = start_id + self.p_t_dim * i + j\n",
    "                    if mask_cand > 0 and mask_cand < sequence_len:\n",
    "                        cur_mask.append(mask_cand)\n",
    "            mask_id = mask_id + cur_mask\n",
    "        mask_id = list(set(mask_id))[:mask_size]\n",
    "        return torch.tensor(mask_id)\n",
    "\n",
    "    # using cluster for frame masking hurts the performance, so just use the naive random sampling\n",
    "    def gen_maskid_frame(self, sequence_len=512, mask_size=100):\n",
    "        mask_id = random.sample(range(0, sequence_len), mask_size)\n",
    "        return torch.tensor(mask_id)\n",
    "    \n",
    "    def finetuningavgtok_1sec(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.v.patch_embed(x)\n",
    "        if self.cls_token_num == 2:\n",
    "            cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "            dist_token = self.v.dist_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
    "        else:\n",
    "            cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.v.pos_embed\n",
    "        x = self.v.pos_drop(x)\n",
    "        \n",
    "        for blk_id, blk in enumerate(self.v.blocks):\n",
    "            x = blk(x)\n",
    "        x = self.v.norm(x)\n",
    "\n",
    "        # Average output of tokens within each 1-second segment\n",
    "        tokens_per_second = x.shape[1] // 60  \n",
    "        x_averaged = torch.stack([torch.mean(x[:, i * tokens_per_second:(i + 1) * tokens_per_second, :], dim=1) for i in range(60)], dim=1)\n",
    "        x_averaged = self.mlp_head(x_averaged)\n",
    "        return x_averaged\n",
    "        \n",
    "\n",
    "    def finetuningavgtok(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.v.patch_embed(x)\n",
    "        if self.cls_token_num == 2:\n",
    "            cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "            dist_token = self.v.dist_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
    "        else:\n",
    "            cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.v.pos_embed\n",
    "        x = self.v.pos_drop(x)\n",
    "\n",
    "        for blk_id, blk in enumerate(self.v.blocks):\n",
    "            x = blk(x)\n",
    "        x = self.v.norm(x)\n",
    "\n",
    "        # average output of all tokens except cls token(s)\n",
    "        x = torch.mean(x[:, self.cls_token_num:, :], dim=1)\n",
    "        x = self.mlp_head(x)\n",
    "        return x\n",
    "\n",
    "    def finetuningcls(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.v.patch_embed(x)\n",
    "        if self.cls_token_num == 2:\n",
    "            cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "            dist_token = self.v.dist_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
    "        else:\n",
    "            cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.v.pos_embed\n",
    "        x = self.v.pos_drop(x)\n",
    "\n",
    "        for blk_id, blk in enumerate(self.v.blocks):\n",
    "            x = blk(x)\n",
    "        x = self.v.norm(x)\n",
    "\n",
    "        # if models has two cls tokens (DEIT), average as the clip-level representation\n",
    "        if self.cls_token_num == 2:\n",
    "            x = (x[:, 0] + x[:, 1]) / 2\n",
    "        else:\n",
    "            x = x[:, 0]\n",
    "        x = self.mlp_head(x)\n",
    "        return x\n",
    "\n",
    "    # masked patch pretraining with discriminative objective\n",
    "    def mpc(self, x, mask_patch, cluster, show_mask=False):\n",
    "        input = self.unfold(x).transpose(1, 2)\n",
    "        B = x.shape[0]\n",
    "        # x in shape (batch_size, sequence_len, embedding dim)\n",
    "        x = self.v.patch_embed(x)\n",
    "\n",
    "        # encode the patch\n",
    "        # size 12(batch_size) * 100(#mask_patch) * 768(hidden_dim), prepare to save the true values of masked samples\n",
    "        encode_samples = torch.empty((B, mask_patch, 256), device=x.device, requires_grad=False).float()\n",
    "        # size 12(batch_size) * 100(#mask_patch), index of masked patches\n",
    "        mask_index = torch.empty((B, mask_patch), device=x.device, requires_grad=False).long()\n",
    "        # size 12(batch_size) * 512(sequence_len) * 768(hidden_dim)\n",
    "        mask_dense = torch.ones([x.shape[0], x.shape[1], x.shape[2]], device=x.device)\n",
    "\n",
    "        # for each audio clip in the batch\n",
    "        for i in range(B):\n",
    "            # randomly generate #mask_patch mask indexes without duplicate\n",
    "            if cluster == True:\n",
    "                # use this if you are masking e.g. 16*16 patches\n",
    "                mask_index[i] = self.gen_maskid_patch(self.num_patches, mask_patch)\n",
    "            else:\n",
    "                # use this if you are masking frame, i.e., 128*2 patches\n",
    "                mask_index[i] = self.gen_maskid_frame(self.num_patches, mask_patch)\n",
    "            # copy the masked embeddings, note gradients are stopped in this path\n",
    "            encode_samples[i] = input[i, mask_index[i], :].clone().detach()\n",
    "            # mask the encode samples with 0\n",
    "            mask_dense[i, mask_index[i], :] = 0\n",
    "\n",
    "        # follow BEIT paper, mask with learnable masking embedding, but no performance diff observed compared with masking with 0s.\n",
    "        mask_tokens = self.mask_embed.expand(B, x.shape[1], -1)\n",
    "\n",
    "        # mask the patch\n",
    "        x = x * mask_dense + (1-mask_dense) * mask_tokens\n",
    "\n",
    "        # pass through the Transformer layers\n",
    "        cls_tokens = self.v.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        if self.cls_token_num == 2: \n",
    "            dist_token = self.v.dist_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
    "        else:\n",
    "            x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.v.pos_embed\n",
    "        x = self.v.pos_drop(x)\n",
    "        #print(\"x before blk.shape\",x.shape)\n",
    "        for blk in self.v.blocks:\n",
    "            x = blk(x)\n",
    "            #print(\"blk(x).shape\",x.shape)\n",
    "        x = self.v.norm(x)\n",
    "\n",
    "        # prediction of the masked patch\n",
    "        pred = torch.empty((B, mask_patch, 256), device=x.device).float()  # e.g. size 12*100*768\n",
    "        for i in range(B):\n",
    "            #  +2 for indexes because skipping the cls and dis token\n",
    "            # we map the output of transformer (768-dim for base models) to 256-dim patch input space, and then dot product with flattened patch input (also 256-dim) to calculate loss.\n",
    "            # alternatively, you can map the output of transformer to 768-dim patch embedding space, and dot product with patch embedding. Performance-wise they are similar, but map to 256 space is more efficient.\n",
    "            pred[i] = self.cpredlayer(x[i, mask_index[i] + self.cls_token_num, :])\n",
    "\n",
    "        # calculate the NCE loss\n",
    "        nce = torch.tensor(0.0).to(x.device)\n",
    "        correct = torch.tensor(0.0).to(x.device)\n",
    "        for i in np.arange(0, B):\n",
    "            # negative samples are from the same batch\n",
    "            # 8/12/2022: has a difference with equation (1) in the ssast paper but (likely) performance-wise similar, see https://github.com/YuanGongND/ssast/issues/13\n",
    "            total = torch.mm(encode_samples[i], torch.transpose(pred[i], 0, 1))  # e.g. size 100*100\n",
    "            correct += torch.sum(torch.eq(torch.argmax(self.softmax(total), dim=0), torch.arange(0, mask_patch, device=x.device)))  # correct is a tensor\n",
    "            nce += torch.sum(torch.diag(self.lsoftmax(total)))  # nce is a tensor\n",
    "        acc = 1. * correct / (B * mask_patch)\n",
    "        nce = nce / (-1. * B * mask_patch)\n",
    "\n",
    "        # visualize the masked area, for probing test only, set show_mask = False for any training/inference.\n",
    "        if show_mask == False:\n",
    "            return acc, nce\n",
    "        else:\n",
    "            if B > 1:\n",
    "                raise Exception('Currently only support single spectrogram probing test.')\n",
    "\n",
    "            self.mask_correct = torch.nn.Parameter(torch.arange(0, mask_patch), requires_grad=False)\n",
    "\n",
    "            pred = input.clone()  # [B, 512, 256]\n",
    "            masked = input.clone()\n",
    "\n",
    "            for i in range(B):\n",
    "                result = [float(t) * 99 for t in torch.eq(torch.argmax(self.softmax(total), dim=0), self.mask_correct)]\n",
    "                pred[i, mask_index[i], :] = torch.tensor(result).reshape(mask_patch, 1).expand(mask_patch, 256)\n",
    "                masked[i, mask_index[i], :] = 99.0\n",
    "\n",
    "            # print(total)\n",
    "            # print(self.softmax(total))\n",
    "            # print(torch.argmax(self.softmax(total), dim=0))\n",
    "            # print(self.mask_correct)\n",
    "            # print(torch.eq(torch.argmax(self.softmax(total), dim=0), self.mask_correct))\n",
    "            # print([float(t)*99 for t in torch.eq(torch.argmax(self.softmax(total), dim=0), self.mask_correct)])\n",
    "\n",
    "            fold = torch.nn.Fold(output_size=([self.input_fdim, self.input_tdim]), kernel_size=(self.fshape, self.tshape), stride=(self.fstride, self.tstride))\n",
    "            pred = fold(pred.transpose(1, 2))\n",
    "            masked = fold(masked.transpose(1, 2))\n",
    "\n",
    "            return pred, masked\n",
    "\n",
    "    # # masked patch pretraining with generative objective\n",
    "    def mpg(self, input, mask_patch, cluster):\n",
    "        B = input.shape[0]\n",
    "        x = self.v.patch_embed(input)\n",
    "        input = self.unfold(input).transpose(1, 2)\n",
    "\n",
    "        # size 12(batch_size) * 100(#mask_patch), index of masked patches\n",
    "        mask_index = torch.empty((B, mask_patch), device=x.device, requires_grad=False).long()\n",
    "        # size 12(batch_size) * 512(sequence_len) * 768(hidden_dim)\n",
    "        mask_dense = torch.ones([x.shape[0], x.shape[1], x.shape[2]], device=x.device)\n",
    "        for i in range(B):\n",
    "            # randomly generate #mask_patch mask indexes without duplicate\n",
    "            if cluster == True:\n",
    "                # use this if you are masking e.g. 16*16 patches\n",
    "                mask_index[i] = self.gen_maskid_patch(self.num_patches, mask_patch)\n",
    "            else:\n",
    "                # use this if you are masking frame, i.e., 128*2 patches\n",
    "                mask_index[i] = self.gen_maskid_frame(self.num_patches, mask_patch)\n",
    "            mask_dense[i, mask_index[i], :] = 0\n",
    "\n",
    "        mask_tokens = self.mask_embed.expand(B, x.shape[1], -1)\n",
    "\n",
    "        # follow BEIT paper, mask with learnable masking embedding, but no performance diff observed compared with masking with 0s.\n",
    "        x = x * mask_dense + (1-mask_dense) * mask_tokens\n",
    "\n",
    "        # go through the Transformer layers\n",
    "        cls_tokens = self.v.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        if self.cls_token_num == 2: \n",
    "            dist_token = self.v.dist_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
    "        else:\n",
    "            x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.v.pos_embed\n",
    "        x = self.v.pos_drop(x)\n",
    "        for blk in self.v.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.v.norm(x)\n",
    "\n",
    "        pred = torch.empty((B, mask_patch, self.fshape * self.tshape), device=x.device).float()  # e.g. size 12*100*256\n",
    "        target = torch.empty((B, mask_patch, self.fshape * self.tshape), device=x.device).float() # e.g. size 12*100*256\n",
    "\n",
    "        for i in range(B):\n",
    "            #  +2 for indexes because cls and dis token\n",
    "            pred[i] = self.gpredlayer(x[i, mask_index[i] + self.cls_token_num, :])\n",
    "            target[i] = input[i, mask_index[i], :]\n",
    "\n",
    "        # calculate the MSE loss\n",
    "        mse = torch.mean((pred - target) ** 2)\n",
    "\n",
    "        return mse\n",
    "\n",
    "    def forward(self, x, task, cluster=True, mask_patch=400):\n",
    "        # expect input x = (batch_size, time_frame_num, frequency_bins), e.g., (12, 1024, 128)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = x.transpose(2, 3)\n",
    "\n",
    "        # finetuning (ft), use the mean of all token (patch) output as clip-level representation.\n",
    "        # this is default for SSAST fine-tuning as during pretraining, supervision signal is given to each token, not the [cls] token\n",
    "        if task == 'ft_avgtok':\n",
    "            return self.finetuningavgtok(x)\n",
    "        elif task == 'ft_avgtok_1sec':\n",
    "            return self.finetuningavgtok_1sec(x)\n",
    "        # alternatively, use the [cls] token output as clip-level representation.\n",
    "        elif task == 'ft_cls':\n",
    "            return self.finetuningcls(x)\n",
    "        # pretraining, masked patch classification (discriminative objective)\n",
    "        elif task == 'pretrain_mpc':\n",
    "            return self.mpc(x, mask_patch=mask_patch, cluster=cluster)\n",
    "        # pretraining, masked patch reconstruction (generative objective)\n",
    "        elif task == 'pretrain_mpg':\n",
    "            return self.mpg(x, mask_patch=mask_patch, cluster=cluster)\n",
    "        elif task == 'visualize_mask':\n",
    "            return self.mpc(x, mask_patch=mask_patch, cluster=cluster, show_mask=True)\n",
    "        else:\n",
    "            raise Exception('Task unrecognized.')\n",
    "\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vision Mamba Config: {'img_size': (128, 512), 'patch_size': 16, 'stride': 16, 'embed_dim': 768, 'depth': 24, 'channels': 1, 'num_classes': 1000, 'drop_rate': 0.0, 'drop_path_rate': 0.1, 'norm_epsilon': 1e-05, 'rms_norm': False, 'residual_in_fp32': False, 'fused_add_norm': False, 'if_rope': False, 'if_rope_residual': False, 'bimamba_type': 'v2', 'if_bidirectional': True, 'final_pool_type': 'none', 'if_abs_pos_embed': True, 'if_bimamba': False, 'if_cls_token': True, 'if_devide_out': True, 'use_double_cls_token': False, 'use_middle_cls_token': False}\n",
      "now load a SSL pretrained models from ssamba_base_300.pth\n",
      "combined_vision_mamba_config {'img_size': (128, 512), 'patch_size': 16, 'stride': 16, 'embed_dim': 768, 'depth': 24, 'rms_norm': False, 'residual_in_fp32': False, 'fused_add_norm': False, 'final_pool_type': 'none', 'if_abs_pos_embed': True, 'if_rope': False, 'if_rope_residual': False, 'bimamba_type': 'v2', 'if_cls_token': True, 'if_devide_out': True, 'use_middle_cls_token': False, 'channels': 1, 'num_classes': 1000, 'drop_rate': 0.0, 'drop_path_rate': 0.1, 'norm_epsilon': 1e-05, 'if_bidirectional': True, 'if_bimamba': False, 'use_double_cls_token': False}\n",
      "Vision Mamba Config: {'img_size': (128, 512), 'patch_size': 16, 'stride': 16, 'embed_dim': 768, 'depth': 24, 'rms_norm': False, 'residual_in_fp32': False, 'fused_add_norm': False, 'final_pool_type': 'none', 'if_abs_pos_embed': True, 'if_rope': False, 'if_rope_residual': False, 'bimamba_type': 'v2', 'if_cls_token': True, 'if_devide_out': True, 'use_middle_cls_token': False, 'channels': 1, 'num_classes': 1000, 'drop_rate': 0.0, 'drop_path_rate': 0.1, 'norm_epsilon': 1e-05, 'if_bidirectional': True, 'if_bimamba': False, 'use_double_cls_token': False}\n",
      "combined_vision_mamba_config {'img_size': (128, 512), 'patch_size': 16, 'stride': 16, 'embed_dim': 768, 'depth': 24, 'rms_norm': False, 'residual_in_fp32': False, 'fused_add_norm': False, 'final_pool_type': 'none', 'if_abs_pos_embed': True, 'if_rope': False, 'if_rope_residual': False, 'bimamba_type': 'v2', 'if_cls_token': True, 'if_devide_out': True, 'use_middle_cls_token': False, 'channels': 1, 'num_classes': 1000, 'drop_rate': 0.0, 'drop_path_rate': 0.1, 'norm_epsilon': 1e-05, 'if_bidirectional': True, 'if_bimamba': False, 'use_double_cls_token': False}\n",
      "pretraining patch split stride: frequency=16, time=16\n",
      "pretraining patch shape: frequency=16, time=16\n",
      "pretraining patch array dimension: frequency=8, time=64\n",
      "pretraining number of patches=512\n",
      "fine-tuning patch split stride: frequncey=16, time=16\n",
      "fine-tuning number of patches=256\n"
     ]
    }
   ],
   "source": [
    "pretrain_path = 'ssamba_base_300.pth'\n",
    "# size = 1024\n",
    "size = 512\n",
    "embed_dim = 768\n",
    "vision_mamba_config = {\n",
    "            'img_size': (128, size),\n",
    "            'patch_size': 16,\n",
    "            'stride': 16,\n",
    "            'embed_dim': embed_dim,\n",
    "            'depth': 24,\n",
    "            'channels': 1,\n",
    "            'num_classes': 1000,\n",
    "            'drop_rate': 0.,\n",
    "            'drop_path_rate': 0.1,\n",
    "            'norm_epsilon': 1e-5,\n",
    "            'rms_norm': False,\n",
    "            'residual_in_fp32': False,\n",
    "            'fused_add_norm': False,\n",
    "            'if_rope': False,\n",
    "            'if_rope_residual': False,\n",
    "            'bimamba_type': \"v2\",\n",
    "            'if_bidirectional': True,\n",
    "            'final_pool_type': 'none',\n",
    "            'if_abs_pos_embed': True,\n",
    "            'if_bimamba': False,\n",
    "            'if_cls_token': True,\n",
    "            'if_devide_out': True,\n",
    "            'use_double_cls_token': False,\n",
    "            'use_middle_cls_token': False,\n",
    "            }\n",
    "# model = AMBAModel(pretrain_stage=False, load_pretrained_mdl_path=pretrain_path, vision_mamba_config=vision_mamba_config)\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "audio_model = AMBAModel(label_dim=50, fshape=16, tshape=16, fstride=16, tstride=16,\n",
    "                           input_fdim=128, input_tdim=size, model_size='base', pretrain_stage=False, load_pretrained_mdl_path=pretrain_path, vision_mamba_config=vision_mamba_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def extract_ssamba_features(audio_model, audio):\n",
    "    audio_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y, sr = librosa.load(audio, sr=16000, mono=True)\n",
    "        print(y.shape)\n",
    "        D = librosa.stft(y, n_fft=210, hop_length=220)\n",
    "        print(D.shape)\n",
    "        #conver to tensor\n",
    "        # D = torch.tensor(D)\n",
    "        # D = D.unsqueeze(0)\n",
    "        print(D.shape)\n",
    "        print(type(D))\n",
    "        magnitude, phase = librosa.magphase(D)\n",
    "        magnitude = torch.tensor(magnitude)\n",
    "        magnitude = magnitude.unsqueeze(0)\n",
    "        print(magnitude.shape)\n",
    "        print(phase.shape)\n",
    "        audio = audio_model(magnitude, task='ft_avgtok')\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000,)\n",
      "(106, 728)\n",
      "(106, 728)\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 106, 728])\n",
      "(106, 728)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (271) must match the size of tensor b (257) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print(audio_model)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_1.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_ssamba_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print(features.shape)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 20\u001b[0m, in \u001b[0;36mextract_ssamba_features\u001b[0;34m(audio_model, audio)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(magnitude\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(phase\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 20\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43maudio_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmagnitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mft_avgtok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m audio\n",
      "File \u001b[0;32m/data6/yaswanthk/miniconda3/envs/aum/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data6/yaswanthk/miniconda3/envs/aum/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 709\u001b[0m, in \u001b[0;36mAMBAModel.forward\u001b[0;34m(self, x, task, cluster, mask_patch)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;66;03m# finetuning (ft), use the mean of all token (patch) output as clip-level representation.\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;66;03m# this is default for SSAMBA fine-tuning as during pretraining, supervision signal is given to each token, not the [cls] token\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mft_avgtok\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinetuningavgtok\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mft_avgtok_1sec\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinetuningavgtok_1sec(x)\n",
      "Cell \u001b[0;32mIn[11], line 347\u001b[0m, in \u001b[0;36mAMBAModel.finetuningavgtok\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    345\u001b[0m     cls_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv\u001b[38;5;241m.\u001b[39mcls_token\u001b[38;5;241m.\u001b[39mexpand(B, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    346\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((cls_tokens, x), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 347\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_embed\u001b[49m\n\u001b[1;32m    348\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv\u001b[38;5;241m.\u001b[39mpos_drop(x)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# mamba impl\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (271) must match the size of tensor b (257) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# print(audio_model)\n",
    "audio = \"chunk_1.wav\"\n",
    "features = extract_ssamba_features(audio_model, audio)\n",
    "# print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AMBAModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 69\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):              \n\u001b[1;32m     42\u001b[0m     vision_mamba_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_size\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m128\u001b[39m, size),\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_middle_cls_token\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     67\u001b[0m     }\n\u001b[0;32m---> 69\u001b[0m     audio_model \u001b[38;5;241m=\u001b[39m \u001b[43mAMBAModel\u001b[49m(label_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, fshape\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, tshape\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, fstride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, tstride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m     70\u001b[0m                    input_fdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, input_tdim\u001b[38;5;241m=\u001b[39msize, model_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrain_stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, load_pretrained_mdl_path\u001b[38;5;241m=\u001b[39mpretrain_path, vision_mamba_config\u001b[38;5;241m=\u001b[39mvision_mamba_config)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio_model, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDataParallel):\n\u001b[1;32m     72\u001b[0m         audio_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDataParallel(audio_model)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AMBAModel' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import sys\n",
    "\n",
    "# from models import ASTModel, AMBAModel\n",
    "import sys\n",
    "import os, csv, argparse, wget\n",
    "import torch, torchaudio, timm\n",
    "import numpy as np256\n",
    "from torch.cuda.amp import autocast\n",
    "import IPython\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Run inference tests for different model sizes.')\n",
    "# parser.add_argument('--model_size', type=str, default='base', choices=['base', 'small', 'tiny'],\n",
    "#                     help='Model size to use for inference tests')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "model_size = 'base'\n",
    "csv_file_name = f'inference_times_{model_size}_amba_batch2.csv'\n",
    "\n",
    "# pretrain_path=f\"/engram/naplab/shared/ssamba/models/amba_{model_size}_300.pth\"\n",
    "pretrain_path = f\"ssamba_{model_size}_300.pth\"\n",
    "\n",
    "if model_size == 'base':\n",
    "    embed_dim = 768\n",
    "elif model_size == 'small':\n",
    "    embed_dim = 384\n",
    "elif model_size == 'tiny':\n",
    "    embed_dim = 192\n",
    "    \n",
    "batch_size = 2\n",
    "# Make the prediction\n",
    "with open(csv_file_name, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Input Size', 'Run Number', 'Inference Time (seconds)', 'Memory Used (MB)'])\n",
    "    \n",
    "    # Test with different input sizes\n",
    "    for size in range(1024, 151680, 512):  # Adjust range and step as needed\n",
    "        for run in range(5):              \n",
    "            vision_mamba_config = {\n",
    "            'img_size': (128, size),\n",
    "            'patch_size': 16,\n",
    "            'stride': 16,\n",
    "            'embed_dim': embed_dim,\n",
    "            'depth': 24,\n",
    "            'channels': 1,\n",
    "            'num_classes': 1000,\n",
    "            'drop_rate': 0.,\n",
    "            'drop_path_rate': 0.1,\n",
    "            'norm_epsilon': 1e-5,\n",
    "            'rms_norm': False,\n",
    "            'residual_in_fp32': False,\n",
    "            'fused_add_norm': False,\n",
    "            'if_rope': False,\n",
    "            'if_rope_residual': False,\n",
    "            'bimamba_type': \"v2\",\n",
    "            'if_bidirectional': True,\n",
    "            'final_pool_type': 'none',\n",
    "            'if_abs_pos_embed': True,\n",
    "            'if_bimamba': False,\n",
    "            'if_cls_token': True,\n",
    "            'if_devide_out': True,\n",
    "            'use_double_cls_token': False,\n",
    "            'use_middle_cls_token': False,\n",
    "            }\n",
    "\n",
    "            audio_model = AMBAModel(label_dim=50, fshape=16, tshape=16, fstride=16, tstride=16,\n",
    "                           input_fdim=128, input_tdim=size, model_size='base', pretrain_stage=False, load_pretrained_mdl_path=pretrain_path, vision_mamba_config=vision_mamba_config)\n",
    "            if not isinstance(audio_model, torch.nn.DataParallel):\n",
    "                audio_model = torch.nn.DataParallel(audio_model).to('cuda')\n",
    "            # (batch, tdim, fdim)\n",
    "            feats = torch.randn(batch_size, size, 128).to('cuda')  # Random data simulating the features\n",
    "\n",
    "            # Start timing\n",
    "            start_event = torch.cuda.Event(enable_timing=True)\n",
    "            end_event = torch.cuda.Event(enable_timing=True)\n",
    "            torch.cuda.synchronize()\n",
    "            start_event.record()\n",
    "            \n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            memory_before = torch.cuda.memory_allocated() / (1024 ** 2)  \n",
    "\n",
    "            # Perform inference\n",
    "            with torch.no_grad():\n",
    "                output = audio_model(x=feats, task=\"ft_avgtok\")\n",
    "                output = torch.sigmoid(output)\n",
    "                \n",
    "            end_event.record()\n",
    "            torch.cuda.synchronize()\n",
    "            # End timing\n",
    "            inference_time = start_event.elapsed_time(end_event) / 1000.0  \n",
    "            peak_memory = torch.cuda.max_memory_allocated() / (1024 ** 2)  \n",
    "            \n",
    "            \n",
    "            writer.writerow([size, run + 1, inference_time, peak_memory])\n",
    "            print(f'Run {run + 1}: Input Size: {size}, Inference Time: {inference_time:.4f} seconds, Memory Usage: {peak_memory:.2f} MB')\n",
    "            del feats, output\n",
    "            torch.cuda.empty_cache()  \n",
    "\n",
    "            \n",
    "            \n",
    "print(f'Inference times recorded in {csv_file_name}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
