{
    "base_model": {
        "model_path": "unsynced/models/model_100.pt",
        "config_path": "unsynced/configs/Wav2Vec2Config.json"
    },
    "downstream_task": {
        "desc": "Physionet-2022 murmur classification",
        "data_preparation": {
            "train_test_csv_folderpath": "unsynced/data_preparation/k_folds",
            "k_fold": "fold_05",
            "save_directory": "unsynced/data",
            "chunk_duration": 10,
            "sample_rate_": 4000,
            "sample_rate": 16000,
            "hop": 2,
            "augment_probability": 60,
            "labels": {
                "Present": 0,
                "Absent": 1
            },
            "augment": {
                "white_noise": {
                    "likelihood": 1,
                    "snr_range": [
                        -10,
                        10
                    ]
                }
            }
        },
        "model_training": {
            "datasets2":["AiSteth", "physionet_2022"], 
            "datasets1":["physionet_2022"],
            "datasets":["AiSteth"],  
            "dir_paths": {
                "trial_folder_path1": "unsynced/data/base_model_1/results/fold_05_normal_aisteth",
                "trial_folder_path2": "unsynced/data/wav2vec2-base/results/fold_01_all",
                "trial_folder_path": "unsynced/data/hubert_base/results/fold_05_aisteth",
                "test": "data_preparation/test"
            },
            "architecture": {
                "desc": "LSTM with scaled dot product attention",
                "model_type": "LSTMWithScaledDotProductAttention",
                "num_layers": 2,
                "bidirectional": true,
                "dropout": 0.1,
                "num_classes": 2,
                "input_dim": 768,
                "hidden_dim": 384,
                "_input_dim": 626,
                "_hidden_dim": 313
                
            },
            "training_params": {
                "batch_size": 32,
                "batch_size1": 16,
                "learning_rate": 1e-3,
                "optimizer": "adam",
                "device": "cuda:5",
                "num_epochs": 20,
                "scheduler": {
                    "mode": "max",
                    "patience": 4,
                    "factor": 0.1
                }
            }
        }
    }
}